
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Mnemnion</title>
  <meta name="author" content="Sam Atman">

  
  <meta name="description" content="Literate Programming is one of those paradigms whose fate is continual reinvention. I&#39;ve been noticing that my software projects start as &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mnemnion.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Mnemnion" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Mnemnion</a></h1>
  
    <h2>A Unit of Analogy</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mnemnion.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/08/03/a-tangled-web-we-weave/">A Tangled Web We Weave</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-08-03T11:13:00-07:00" pubdate data-updated="true">Aug 3<span>rd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://www-cs-faculty.stanford.edu/%7Euno/lp.html">Literate Programming</a> is one of those paradigms whose fate is continual reinvention. I&#39;ve been noticing that my software projects start as Markdown. It stands to reason that they should end up as Markdown as well.</p>

<p><a href="https://help.github.com/articles/github-flavored-markdown">Git Flavored Markdown</a>, in particular, is crying out for a literate, multi-model programming system. The mechanism of named fenced code blocks lets one put multiple languages in a single file, and they will already be syntax highlighted according to the named language. </p>

<p>As literate programming is for the ages, we shall call our system <a href="README.md">Marmion</a>. The weaver shall be known as <a href="athena.md">Athena</a>; the tangler, <a href="">Arachne</a>.</p>

<p>If at all possible, we don&#39;t want to touch GFM itself. Therefore, here are some principles:</p>

<ul>
<li><p>Code in fenced code blocks is extracted, macro-expanded, and executed in whatever ways are appropriate.</p></li>
<li><p>Macros must employ patterns not used in a given language; therefore, we must be able to define those patterns.</p></li>
<li><p>All configuration happens in special code blocks, called <code>```config</code>:</p></li>
</ul>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">{</span> <span class="ss">:name</span> <span class="s">&quot;A config file&quot;</span>,
</span><span class='line'>  <span class="ss">:format</span> <span class="ss">:edn</span>
</span><span class='line'>  <span class="ss">:magic-number</span> <span class="mi">42</span> <span class="p">}</span> <span class="c1">;this is actually tagged ```clojure</span>
</span></code></pre></td></tr></table></div></figure>

<ul>
<li><p>Code in regular unfenced code blocks is not included in the weave. Nor are fenced code blocks that aren&#39;t reached from the top macro. The code above, for example, <em>will not</em> be in the finished weave, because it is exemplary.</p></li>
<li><p>All text ends up in the tangle, which is an HTML file. No other tangle format is contemplated. </p></li>
<li><p>If standardized, the tangle format will not be specified, only the markup format and the requirements for the subsequent weave. HTML is a moving target, as is visual display in general. </p></li>
<li><p>The Markdown may be extended, but only in the same way as any other code: by specifying a macro template and expanding it from provided code. It is the macro-expanded Markdown which is tangled and woven.</p></li>
<li><p>Corollary: the Markdown is macro expanded before anything in a code block.  </p></li>
<li><p>Corollary: the Markdown macro will be standard. There should be no reason to include it. Because Clojure is the implementation language, and has a defined reader macro syntax, this is already true of Clojure(Script).</p></li>
<li><p>The weaver should visit all internal links in search of code. Some tag in HTML form should be provided so that fully-marked-up links, so tagged, will also be followed in search of exterior code. </p></li>
<li><p>If exterior code is requested, it is added to the source as a fenced code block. The tangle will preserve the link directly above the code block. Some sensible effort will be made to infer the code format from the file extension. This is to be done before macro expansion, so that if there are macros in the exterior code, they will be expanded.</p></li>
<li><p>We should maintain a set of canonical macro patterns for languages, to encourage mutual compatibility in source and tangled code.</p></li>
<li><p>No mechanism for transclusion on the file level will be provided. The file structure of the Markdown is the file structure of the tangle. Working around this using the tagged-link method will leave a broken link in your tangle.</p></li>
</ul>

<p>This is the sort of project that we can tackle in stages. The most important part is the weaver, because we have a fine tangler in the form of <a href="http://jekyllrb.com/">Jekyll</a>. </p>

<p>This is a job for <a href="http://clojure.org">Clojure</a>. The weaver and perhaps the tangler will be Clojurescript compatible in the narrow sense, but useless unless Instaparse is ported, which seems unlikely, though you never know. </p>

<p>Clojure is chosen for a few reasons. <a href="https://github.com/edn-format/edn">EDN</a>, for one, which will be the format of any <code>```config</code> code block. Also because of <a href="https://github.com/Engelberg/instaparse">Instaparse</a>, for which the usual regular-expression based markup approach is a strict subset of capabilities. It has the best story I&#39;m aware of for setting regular expressions declaratively in a data format, which is exactly how we will provide macros. </p>

<p>To be clear, this will let us syntax highlight a provided macro in a distinctive way, and put things like the colors to use right in the markdown. This is only useful with a completed weaver; Pygments will get the macros wrong but this is a minor stylistic matter which can be corrected by retangling with a better highlighter. </p>

<p>Instaparse is my go-to choice for writing flexible parsers that are meant to be shared, so Clojure it is. I hope Instaparse catches on to the point where it becomes core, and hence worth maintaining separate <code>.clj</code> and <code>.cljs</code> versions. </p>

<p>The first, and most important step, is writing <a href="athena.md">Athena</a>, the weaver. The weaver does the following: finds all the <code>```config</code> code, parses it to configure itself, then goes after the code blocks, and uses the macros and config information to construct the weave. Finally, it calls the trigger file, which must contain everything needed to build the weave into an executable, or whatever the final product is.</p>

<p>The tangler, <a href="">Arachne</a>, should be a <a href="https://github.com/mnemnion/jekyll">fork of Jekyll</a>, with a low surface area of interaction. What I mean by this is that merges between the bases should avoid touching one another&#39;s files wherever possible. The only changes I contemplate personally is to plug-replace the syntax highlighter, for several reasons. </p>

<p>Pygments requires one to write actual code to markup a new format. This is distasteful. Also, we need to markup the macros, which we won&#39;t know until we weave the code. Furthermore, a static syntax highlighter should be based on a powerful parser, not a regular engine janked up with extra Python. For pity&#39;s sake. </p>

<p>If Marmion becomes popular, someone might want to write advanced capabilities: putting compatible code in a REPL, for example, or linking to one from the code, or linking to the line number in a public Github repository generated by the weaver. The last is particularly powerful. All of this will assuredly be easier with a parser-backed tangler. </p>

<p>This is the only way I have to tackle large problems: recursing through the Big Project until I hit something atomic and critical to further progress. Arc leads to GGG, which will benefit greatly from a literate style, which leads to Marmion. Marmion built, writing GGG in an understandable way becomes possible. </p>

<p>I think I&#39;ve painted myself into a corner, as I can&#39;t think of anything offhand which I need to write in order to write Marmion. </p>

<p>Time to generate more Markdown!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/27/syntax-for-literal-strings/">Syntax for Literal Strings</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-27T10:09:00-07:00" pubdate data-updated="true">Jul 27<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I find it somewhat astonishing that the languages with which I&#39;m familiar still start and end strings with the same character. It is as though we used <code>|</code> for <code>{</code> and <code>}</code> in code blocks and relied on context to figure out if it was <code>begin</code> or <code>end</code>. </p>

<p>Incidentally, it&#39;s quite possible to write a language this way, and an interesting exercise. <code>for | i = 0 ; i &lt; 2 ; i++ || codeBlock |</code> should parse just fine. Heaven help you if you misplace anything. </p>

<p>Check out <a href="https://en.wikipedia.org/wiki/Delimiter#Bracket_delimiters">bracket delimiters</a> on the Wiki. Two of these things are not like the others. Those two are used preponderantly for strings. </p>

<p>It&#39;s clear enough how it happened. A string has an obvious mapping to literary quotation: <code>&quot;That&#39;s what she said!&quot;</code>.  ASCII gives us exactly three options: <code>&#39;</code>, <code>`</code>, and <code>&quot;</code>. <a href="http://c-programming.itags.org/q_c-programming-language_16297.html">It turns out</a> that C was defined using 91 characters, and <code>`</code> was not among them. </p>

<p>Meta enough, I&#39;m writing this in Markdown, and to type <code>`</code>, I must type <code>`` ` ``</code>. I will leave how I typed <code>`` ` ``</code> as an exercise for the reader. </p>

<p>So C chose <code>&quot;</code> for string syntax, and <code>&#39;</code> for characters, and these decisions made sense, somewhere in the mists of time. C also initiated the proud tradition of string escaping, which wasn&#39;t invented to get around the delimiter problem, but which can be used for that purpose in a hacky way. String escaping is so you can say <code>\n</code> and get a newline, the incidental benefit is you can say <code>\&quot;</code> and get a <code>&quot;</code>, hence one may include any character in such a string. Two backslashes is of course <code>\\\\</code>. One gets used to it. </p>

<p>Oh hey, just for fun, why not write a regex that will match such strings? Won&#39;t take you long, I promise. I&#39;ll be right here!</p>

<p>To the point. In typography, we don&#39;t do this. We start quotations with <code>‚Äú</code> or <code>‚Äü</code> and end them with <code>‚Äù</code>. On the <a href="http://en.wikipedia.org/wiki/%C2%AB">Continent</a>, <code>¬´</code> and <code>¬ª</code> are used, and this would be my preference as they are much easier to tell apart and don&#39;t have two choices for the opening delimiter. If you follow the link, It turns out they are used both <code>¬´this way¬ª</code> and <code>¬ªthis way¬´</code> and even <code>¬ªthis way¬ª</code> by Finns (<a href="http://en.wikipedia.org/wiki/Finnish_language">of course</a>). We favor the first, because all other brackets in computer programming are inward facing <code>&lt;{[(like so)]}&gt;</code>.</p>

<p>What&#39;s the point? They aren&#39;t on standard keyboards in the US; while any worthwhile editor can get around this, there&#39;s a pain point there. Some people will argue a virtue in using ASCII for source code, and while those people <a href="https://github.com/cgyarvin/urbit">have a point</a>, the ship sailed a long time ago. We use Unicode, and it isn&#39;t going anywhere. </p>

<p>The point is that, without proper left-right matched strings, you cannot literally quote your own source code within your source code. This is damaged, for any language that lets you evaluate at runtime (the interesting ones IOW). If we use <code>¬´</code> and <code>¬ª</code>, we can use bog-standard reference counting to assure that any properly-balanced literal strings in the source code get quoted. Since in this imaginary syntax a bare <code>¬ª</code> not balanced on the left with a <code>¬´</code> is a syntax error, any correct program can be embedded. </p>

<p>If, for any reason, you need a bare <code>¬ª</code>, why not use the ISO standard SHA-1 hash of the Unicode value of <code>¬ª</code>? Why not indeed. It then becomes impossible to literally quote that one hash, which is officially the point where it is perverse to pursue the matter further. Concatenate for that one. </p>

<p>To be clear, <code>&quot;</code> for escaped strings is concise and well understood, and with enough convolutions one may write as one pleases. It&#39;s syntax such as <code>&#39;&#39;&#39;</code> for literal strings that grates against my sensibilities. </p>

<p>Clojure has no syntax for literal, multi-line, unescaped strings. That&#39;s too bad; no one does syntax like Rich Hickey, and I suspect that the inadequacy of existing options plays a role here. He may not be willing to go off-keyboard, but I feel that the <code>¬´</code> and <code>¬ª</code> syntax has a lot to offer. Certainly Europeans would be pleased. </p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/27/introduction-to-the-architecture/">Introduction to the Architecture</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-27T00:00:00-07:00" pubdate data-updated="true">Jul 27<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Hello, World!&#8212;<br>
layout: post<br>
title: &quot;Introduction to the Architecture&quot;<br>
date: 2013-07-27 12:20<br>
comments: true<br>
published: false</p>

<h2 id="toc_7">categories: Code, Arc</h2>

<h2 id="toc_8">Notes on a Sensible Environment for Computation.</h2>

<p>The goal is, superficially, a simple one. I wish to be able to turn on my computer, and reset it to one year ago. I can then move around inside that space and do new things, like fetch information from one year ago, rerun programs exactly as they ran then, and the like. </p>

<p>That&#39;s not the whole goal. That&#39;s a taste of the goal. It suffices to start the conversation.</p>

<p>My name for this project is the Arc. <a href="http://www.paulgraham.com/arc.html">Paul Graham</a> will just have to get used to that; the concept is not his, and the word is too ancient and noble to languish as an experimental dalliance. To differentiate, we may call it Araka, and I will use the two interchangeably. There is no difference, any more than LISP and Lisp are two canonically different things. Vowels simply aren&#39;t that important unless they begin a word. Nor does the distinction between c and k matter, when they are sounded the same. </p>

<p>This is another taste of the goal. The Arc is Architecture, not Environment. </p>

<p>Hi. I&#39;m your host, mnemnion. My day job is to make heterogenous computing environments of multi-core CPU and GPU architectures do computation as fast as possible. When I say <a href="http://en.wikipedia.org/wiki/Von_Neumann_architecture">John von Neumann</a> is fired, I mean it.</p>

<p>For another taste of the goal, I present <a href="http://www.loper-os.org/?p=284">LoperOS</a>. Loper would appear to be hard at work on his own version of the goal. I eagerly await. </p>

<p>The Seven Laws of Sane Personal Computing are <a href="http://en.wikipedia.org/wiki/Three_Laws_of_Robotics">Asimovian</a> in scope and breadth. Certain clauses, and the soul of Rule IV, are sociopolitical in nature: Show me a readable program and a compiler for it, and I will show you complete gibberish that does the same thing. This should not keep us from doing our level best, and is no excuse at all for failing at the purely technical points. </p>

<p>Another player in the game is <a href="https://github.com/cgyarvin/urbit">C. Guy Yarvin</a>, whose Urbit is a credible attempt at the whole shebang that you can actually go and marvel at right now. It&#39;s written in Martian and there is no dictionary, the Rosetta is in C and hard going, and <a href="http://moronlab.blogspot.com/">no, I am not exaggerating</a>. The goal appears to be to write the damn thing rather than, I dunno, blogging about it. Laudable; I eagerly await. </p>

<p>What with the aforementioned day job, when I write code on my own time, <a href="https://github.com/mnemnion/emojure">I go light</a>. Whimsical, even. What I&#39;m going for with these posts is an exploration of the <a href="http://en.wikipedia.org/wiki/The_Nature_of_Order">patterns</a> that will eventually make up the Architecture. </p>

<p>An aside: if you haven&#39;t read <em>The Nature of Order</em> you&#39;ve missed what Alexander has to offer. <em>A Pattern Language</em>, while a brilliant gem, is not the Magnum Opus. </p>

<h2 id="toc_9">Arc and Arcism</h2>

<p>The Arc is part of a larger project, the arcist tendency. The Free Software Movement, which is the only technocratic political movement of any significance thus far, is thoroughly rooted in International Socialism. I say that with all affection, and hope RMS would agree, though he may prefer to say &quot;progressive&quot;. I&#39;m all about <a href="http://en.wikipedia.org/wiki/Emic_and_etic">emic</a> vocabulary; progressive it is. </p>

<p>The Arc is in this same sense a vehicle for arcism. There is no sense in which the Arc can succeed on its own, as will become clear enough as we explore. As arcism does not rely on controlling the State (though flourishing under such conditions), a modest success at forming Arcist society will suffice for modest success in the Architecture. Modest success is sufficient to the task at hand. </p>

<p>As it happens, I&#39;m making both the Arc and arcism up as I go along. I&#39;ll do what I can to make them separate posts. </p>

<p>To illustrate the difference of approach, we may consider licenses. An arcist considers contracts which cannot be vigorously enforced to be suspect, akin to a pact with a demon, and a weak-willed one at that. The GPL, with its sticky viral influence and lax enforcement in practice, is a source of great amusement.</p>

<p>The arcist recognizes several states code can be in: unavailable, for example, or encrypted with a key that is believed secure at present, or in the public domain. We favor the public domain for anything interesting: it is the nature of software to be most broadly useful if the source code is readily available. </p>

<p>We may also suggest an old-fashioned way to get paid for all this open-source code: guild up and shake the rest of society down for our share of the loot. We are open to other suggestions that are sensible and reality-respecting. </p>

<p>There are&#8230; very few servants of the Emperor at present. The Arc is made of purest vapor. Let us proceed to condense, and see what may trickle into our flask.</p>

<h2 id="toc_10">Rationale</h2>

<p>Two questions worth asking: Why do this Great Work of reimplementing All the Things? Granted that it&#39;s worth doing, what am I bringing to the table? </p>

<p>I stole Arc because naming things is the Second Hard Problem, and arc- solves it. The Arc runs on the Arcitecture, a physical platform that runs ArcOS. Information travels across the Network (yep, same Network) and is cooled and stored via the Arcive protocol. The system language is Araka, or Arc if you prefer. </p>

<p>This intensive focus on the sensory is characteristic of the entire project. Arc, as pronounced by Americans, is a hard word for much of the rest of the world. <code>a(r|l)…ôk…ô</code> can be broadly realized by essentially everyone. </p>

<p>I am a representation nerd. Ask me about the connection between astrology and abstract algebra sometime. No, really, ask me this as often as possible, because I&#39;m not good enough at explaining it yet to write it down. </p>

<p>This drive led me to develop Phon, a writing system, featural in nature, with the same scope as the International Phonetic Alphabet. Phon deserves its own separate series of blog posts, which really should be published before this one. You can write it in all four canonical directions with minimal confusion. That took some doing; the manual runs 180 pages at present, in trade paper format. It should take maybe two weeks to teach a literate ten year old to write her own language, in her preferred direction. </p>

<p>Phon lies at the intersection of linguistics, representation theory, abstract algebra, Hermetics, and Tolkien studies. The astute reader may notice that I have a knack for naming things. Cache validation is less my style, and I have been known to be off by one, from time to time. A youth misspent with Pascal will do that to ya. </p>

<p>One may at least say that I&#39;m coming at the project from a distinctive angle. I believe that reaching the goal begins with representation, and am confident in saying that I&#39;m the only person on the planet, right now, who has read the books I consider critical.<sup><a href="">[citation needed]</a></sup></p>

<p>Meanwhile, I haven&#39;t read all of <em>your</em> critical books, dear Reader. Suggestions are welcome. </p>

<h2 id="toc_11">Representation</h2>

<p>It&#39;s all zeros and ones, kids. Zeros and ones. Everything else is metaphor.</p>

<p>Our metaphor is dominated by typography. You could cast the entirety of Unicode in lead, bring it back 300 years, and induce quivering orgasm in the printers of the day. It would be quite the heavy box. </p>

<p>Code is textual for a reason, tamper with that at your peril. But serious face, folks: with 64 bits of Unicode, largely barren, what earthly sense does it make to represent <strong>executable code</strong> with the same characters you kiss your mother with?</p>

<p>Nope, we keep reusing those bottom bytes like a bunch of monkeys. UTF-16 is still out there, Emoji is a mess of shims and image embeds, and this is not the worst of it. The code points mean only one thing: a name, and a shape that hopefully can be recognized as the same across fonts that goes with the name. üí©, PILE OF POO, Unicode: U+1F4A9 (U+D83D U+DCA9), UTF-8: F0 9F 92 A9.</p>

<p>Do you see the Poo, dear Reader? Try Firefox.</p>

<p>We can only burn the fields and start anew. Somewhere in a dusty corner of our Representation Format, we shall find the Unicodes, along with the all-important canonical translation matrices which allow archaeologists to sensibly render the fragments of the past and make them actually useful again. </p>

<p>MIME is a bit closer to the point, while missing the target entirely. MIME is, from our perspective, just a bunch of bullshit tacked on to the beginning of a file that may or may not help you figure out what the fuck to do with it. That it works well enough in practice is a miracle of discipline. </p>

<p>A useful header would say &quot;the following content is of type Foo. Its identity may be hashed as <code>Q222a27db79ac39dd6ba2fc1901d6b69c</code>, and the content may be validated for type using a function whose hash is <code>222a27db79ac39dd6ba2fc1901d6b69c</code>&quot;. </p>

<p>Entropy being what it is, white noise can be encoded into any data-only format. We cannot expect to assure that an mp3 contains music, nor that a Unicode string can be meaningfully displayed at all, there being many code points that are set aside for private use. </p>

<p>We can validate that Javascript is Javascript, however, by loading it into an interpreter without errors. How much confidence this gains you varies by language. </p>

<p>This is going backwards, however. JSON can be validated for type and could be usefully transmitted with a header as described. It would be a modest improvement. It&#39;s still Unicode, which means any content it provides is buried in some implementation somewhere and subject to rot. The fact that a human could read it and partially decode it is cold comfort. </p>

<p>Part of the goal is to allow archaeologists a fighting chance at decoding 500 year old partially degraded thumb drives. We have, maybe, one shot at this, before Unicode takes on the strength of DNA. </p>

<h2 id="toc_12">Why we care</h2>

<p>There are only two formats, text and binary. Everything else is tacked on. Here&#39;s a number: 42. It&#39;s represented as Unicode, and if I represented it as, say, an integer, it couldn&#39;t coexist in this Markdown file. I would have to put it somewhere else or do something hacky like Base64 encode it. </p>

<p>If it&#39;s binary, it&#39;s either implementing some spec or it&#39;s homebrew. MIME may help you figure out the former, or it may not. There is nothing even vaguely resembling consistency or regularity anywhere in binary land, and the relationship between the textual world and the blobosphere is uneasy. </p>

<p>Where text is concerned, ASCII at least had the virtue of being somewhat narrowly defined in terms of (mostly) glyphs with distinct shapes that most humans can tell apart. Unicode offers no such promise. </p>

<p>At some point, we&#39;re going to be hashing everything and chunking it out onto the network. Data has to represent the same way, in part and in aggregate, for this to work. The only possible shape is a sort tree, so that&#39;s what we&#39;ll end up using. </p>

<h2 id="toc_13">Section</h2>

<p>What we need is a single format that can resolve all conceivable data and code. That&#39;s not as whacky as it sounds: we have hundreds of equally bad formats for doing this already. Most of them are ASCII or Unicode, of which my opinion is clear. This is computation we&#39;re talking about; it&#39;s all zeros and ones, kids. </p>

<p>Here are some of the patterns which constrain this format:</p>

<ul>
<li><p>Data types are defined in a single fashion, that doesn&#39;t differentiate in principle between standard and extended types. </p></li>
<li><p>Data is composable, a single logical file may contain an arbitrary combination of types, and the operating environment can be relied upon to do sensible things with those compositions. </p></li>
<li><p>New types are, in general, old types with new constraints on their composition. </p></li>
<li><p>All data is sortable, such that if the order is arbitrary for a grouping of data, it is encoded the same way each time. This is critical for deduplication of content in the Arcive. </p></li>
</ul>

<p>To contrast this approach with the state of the art: a website contains a logical structure in the form of files and directories, a server that can present a second, logically distinct superstructure of the same format through URLs, and finally pages, presented to the user, which fetch down this content in yet another logical order provided by the formatting of the HTML et al. </p>

<p>In Arc, we present a hash to the network, and chunks of the content arrive until we have enough to display it. The data structure contains text, images, logic, and whatever else we want it to have, including placeholders with hashes that can fetch down yet more content, video shall we say.</p>

<p>We would like to not have to include an entire video in order for the value of the video to be a part of the identity of the container (say the page it&#39;s embedded in). We also don&#39;t want a page to have a different identity depending on whether the content was fetched or physically included. Clearly, our metaformat is nothing but a concatenation of hashes which is itself hashed to provide the identity. </p>

<p>This means once you create a lolcat, it is one and the same lolcat from the perspective of every person who views it and every context in which it is embedded. They are all served from the same hash; as many extra copies are kept around on the Arcive as are convenient, and no more. The minimum is three.  </p>

<p>Also, if you copy and paste the Gettysburg Address from a website, you should end up with the same Gettysburg Address, not a different one. This is transclusion and we want to have it. We can have it, if we give up on the idea that information should have a physical canonical source on the network from which we retrieve it. </p>

<p>Right now, transclusion is called hotlinking, and is bad form. Jesus wept. It seems like a small matter when it&#39;s lolcats, but when it&#39;s multi-GiB scientific data sets, it makes a difference. Right now, a URL citation says &quot;well, we found something here once that was what we&#39;d like you to look at. Good luck!&quot;. </p>

<p>What is needed is a name for data, not an address. A citation should say &quot;this is the identity of the data in question. If you find something with this identity, it is that to which we refer&quot;. An address, if provided, simply says &quot;the computer at this location can probably find the data in question&quot;.</p>

<h2 id="toc_14">Representation and Resilience</h2>

<p>Choosing the wrong level of representation can have severe consequences on resilience. Sound encoding is a good example. A sensible format for sound would treat encoding as entirely separate from what a track <em>is</em>. Not only that, it wouldn&#39;t rely on promises, such as a header that says &quot;this file definitely isn&#39;t Never Gonna Give You up&quot;. It would say something like &quot;regardless of encoding, you&#39;ll find the following sonic fingerprint if you analyze the track with this piece of logic&quot;. The logic would do what our ears do, basically. Two files containing the same song in different encodings would have the same sonic fingerprint header.</p>

<p>This doesn&#39;t have to be pass / fail, either, that&#39;s merely the simplest implementation. For bitmapped data, a mild Photoshopping could still provide say 90% confidence that the file is &#39;the same image&#39;. For anything with a canonical sensory form, this kind of validation works, and there are plenty of proprietary solutions built on this premise: Google Reverse Image Search, Shazaam, and Soundhound, to name three. </p>

<p>Google also does a good job of detecting what natural language a passage is written in. It&#39;s the same trick. The equivalent test for a passage of text would involve OCR on the bitmap that the environment generates to display the text. </p>

<p>The technique is surprisingly general and works for any static representation of data which is ultimately presented to the senses. It cannot tell you if two games written in Python and Clojure are the same game, any more than it could tell you if a movie and a book have the same plot. It could tell you if an audio book and a text file have the same text, however, or take a good guess at it. </p>

<p>While hashes provide a guarantee of exactitude, this kind of fingerprinting can provide a guide to similarity. </p>

<p>There is another kind of exactitude beloved of computers, that of type. Hashing is for identity, for type, we need some other approach. </p>

<h2 id="toc_15">More Unicode Bashing</h2>

<p>There are few topics more muddled in our field than what a type &#39;is&#39;. I mean something relatively simple: that there exists a function which can take a certain input and validate that it may be treated as of a certain type. For instance, we may define a degenerate type, Blob, the validation function for which simply returns true.</p>

<p>This is also the validation function for ASCII, and hence in principle for Unicode. In practice, Unicode is such a beast that one can often reject arbitrary data as unlikely to contain it, given the number of barren code points. </p>

<p>Anyone from the DOS era remembers loading binaries into a text editor, and the resulting beeping and screen vomit. It is possible to interpret any data at all as ASCII, though this is unwise. Off on <a href="http://moronlabs.com">mars</a>, cgy is embracing this peculiarly arithmetical relationship between ASCII and the low numbers to do voodoo. I see the temptation: it&#39;s here, it&#39;s queer, and we&#39;re used to it. </p>

<p>My beef with Unicode begins with its basic paucity. The logic is that of English and Latin writing, falling apart as soon as one reaches French (e, √© etc. have a dictionary order which is not preserved) and becoming wholly ruined somewhere beyond the European mind. Ge&#39;ez, for an example, has a relationship between the characters that isn&#39;t preserved by writing them all out, while the Hanzi are made of radicals, damnitall, they are in no sense some named flat collection of code points and it&#39;s a crying shame to treat them that way. Check out a Chinese input form for how the logic of Hanzi should be handled. There are options. Better options!</p>

<p>It gets ridiculous, and dangerous, with a practice that is universal and placidly accepted: users are encouraged to input text using the same encoding as the interpreted language running the logic governing the local environment. The mind boggles. There has to be a better way. </p>

<p>In my own little backwater, I am also peeved that Unicode&#39;s &quot;one code point per glyph&quot; policy ends up overloading most of the glyphs used by the IPA to represent sound. If I type e, you have no idea what I meant, and Unicode can&#39;t help you. It sucks the root: I can use visual tricks to inform you, the reader, of my intention, but the computer gets left out. </p>

<p>I could go on. I suspect I shall. For now, suffice to say that it is to our advantage to design types which can be validated, and if we can do so rapidly, so much the better. </p>

<h2 id="toc_16">Functional Validation.</h2>

<p>The idea couldn&#39;t be simpler. You have a chunk of data and some reason to believe it might be, say, music. You run it through a function, which may examine it but not alter it, and the function does things. It returns a verdict, true or false. </p>

<p>The function can and should be anything. It is to our advantage if the heavy lifting is done by a grammar. Grammars can be ambiguous, which is a thorn for interpretation but can be a great boon for validation. They are also declarative, serving to isolate at least some of the semantics of execution from the constraints expected.</p>

<p>This is about more than running differently on different architectures. A grammar may be used exactly, in a linear fashion, or it may be used statistically, to provide a degree of confidence that a file is more-or-less of a certain type. This is useful when files are damaged, missing, or when we must make an initial guess as to type because we have no clues. </p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/06/17/homoiconicity-and-data-forms/">Homoiconicity and Data Forms</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-17T14:52:00-07:00" pubdate data-updated="true">Jun 17<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="toc_6">Representation of Data in Structured Programs.</h3>

<p>Today we&#39;re going to discover a programming language. We&#39;re going to start by contemplating the idea of code as data. </p>

<p>LISP, and by the all-caps I mean the original flavours, had two fundamental forms: atoms, and lists. As Lisp grew up, the lists became able to represent any sort of data type, but at the expense of a certain homoiconicity. </p>

<p>That&#39;s a controversial assertion, but hear me out. A list in a Lisp is a bunch of cons cells, it&#39;s a specific data structure used by default to do pretty much anything. Since the first position (first second third) has a function or a macro, you can fake, say a hash, by saying something like (hash a a-prime b b-prime) but here&#39;s the problem: that&#39;s not homoiconic to your data anymore. Not in a way that accords with modern expectations. </p>

<p>Let&#39;s talk about JSON. Now, JSON is homoiconic to your data. <code>{}</code>? Object. <code>[]</code>? List. <code>&quot;&quot;</code>? String. <code>(1-9)(digits*)</code>? Number. And so on. </p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/06/17/homoiconicity-and-data-forms/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/06/17/an-introduction-to-ent/">An Introduction to Ent</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-17T10:11:00-07:00" pubdate data-updated="true">Jun 17<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>ent is a new approach to code creation. It is (will be) an editor and library that works on parse trees, rather than on files, and registers all changes as <a href="http://www.codecommit.com/blog/java/understanding-and-applying-operational-transformation">operational transformations</a>. It does so through the medium of familiar code files, but these may be thought of as an interface to the code, and as a product of it, similar to the executable binaries produced by a compiler. </p>

<h3 id="toc_0">Parse Aware Editing of Structured Files</h3>

<p>ent&#39;s major rationale is parse-awareness. It will, in general, not allow you to type invalid code, though this can always be overridden. It will parse your code as you create it, storing the resulting file as a series of operational transformations on the parse tree. As a language is more thoroughly defined within ent, this enables REPL-like instant feedback and sophisticated refactoring. </p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/06/17/an-introduction-to-ent/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/08/03/a-tangled-web-we-weave/">A Tangled Web We Weave</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/27/syntax-for-literal-strings/">Syntax for Literal Strings</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/27/introduction-to-the-architecture/">Introduction to the Architecture</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/17/homoiconicity-and-data-forms/">Homoiconicity and Data Forms</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/17/an-introduction-to-ent/">An Introduction to Ent</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Sam Atman -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
