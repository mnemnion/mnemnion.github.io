<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Mnemnion]]></title>
  <link href="http://mnemnion.github.io/atom.xml" rel="self"/>
  <link href="http://mnemnion.github.io/"/>
  <updated>2014-02-03T09:39:42-08:00</updated>
  <id>http://mnemnion.github.io/</id>
  <author>
    <name><![CDATA[Sam Atman]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Plural Forth Words]]></title>
    <link href="http://mnemnion.github.io/blog/2014/02/03/plural-forth-words/"/>
    <updated>2014-02-03T08:16:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/02/03/plural-forth-words</id>
    <content type="html"><![CDATA[<p>This is a simple pattern that points to Forth&#39;s expressiveness and philosophy.</p>

<p>Most words do one thing, and do it well. Sometimes you want to do that thing several times. </p>

<p>In Forth, this is very easy and natural to express. For example, the word <code>key</code> will block until a key is available, and return it. Sometimes, at the REPL in particular, you want to do this multiple times. So we define this word: <code>: keys 0 do key loop ;</code>, and say <code>3 keys</code>. This simply calls <code>key</code> 3 times. </p>

<p>We may approach this level of terseness in other languages, of course. In Lisp we may have <code>(key)</code> and <code>(key 3)</code>, Lua would offer <code>key()</code> and <code>key(3)</code>. Forth words can&#39;t natively know how much of the stack belongs to them, so variadic functions are harder to write. It is impossible to beat the terseness and clarity of <code>key</code> <code>3 keys</code> in use, and the second definition is transparent. </p>

<p>Forth itself uses this custom. <code>cell</code> gives the number of bytes in a cell, while <code>1 cells</code> multiplies 1 by that number, giving the same value. In general, a plural word <strong>must</strong> be proceeded by the number of repetitions. </p>

<p>The syntax of Forth is brutally simple, allowing for a rich semantics. The most important decision: whitespace is (almost) always important. This was made when Fortran was popular; in original Fortran, whitespace is literally never important, meaning <code>foo bar baz</code> and <code>foobarbaz</code> are always the same program. </p>

<p>Consequently, any printable character within a word is fair game. Schemers and friends are accustomed to boolean functions that look like <code>test?</code>, which I&#39;m sure was heady fun after decades of <code>test-p</code>. Forthwriters do this as well. </p>

<p>High-level Forth ends up looking like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>: clickloop
</span><span class='line'>  begin 
</span><span class='line'>      event
</span><span class='line'>      event-respond
</span><span class='line'>      1 .left?
</span><span class='line'>  until
</span><span class='line'>  ;</span></code></pre></td></tr></table></div></figure> 

<p>Anyone can read this. <code>1 .left?</code> is not entirely obvious. The <code>.</code> suggests it&#39;s printing something, and the <code>?</code> suggests that it&#39;s testing something. If it just said <code>left?</code> most Forth programmers would conclude that it&#39;s setting the test that <code>until</code> checks. This is actually handled by <code>event-respond</code>, <code>.left?</code> is a debug function that prints the stack if <code>event-respond</code> leaves values behind. </p>

<p>All of this is customary, and should probably remain so. Parsing within a Forth word breaks some important contracts, notably the dictionary. I&#39;ve been mulling over a modular Forth dialect that parses within a word for exactly one reason, access to words defined in another module that are overloaded. So if you already have an <code>event</code> word, you can say <code>event.:book</code> and get the <code>event</code> word from some other book in your search chain. Since the effect of a vocabulary word is to leave its token on the stack, <code>event .: book</code> could just be the word <code>.:</code> checking the <code>event</code> wordlist for the word <code>book</code>. The compressed form is possibly Forthright, in that the effect is to either interpret or compile a single word. If we used <code>event .: book</code> we would expect 3 words to be compiled, though it is quite possible to have 3 compile-time words (or more) produce a single compiled token, such as <code>: example [ 2 3 + ] literal ;</code> compiles one word, the literal value <code>5</code>. </p>

<p>Adding parsing to Forth words is pure Sith and should be done with great care if at all. Retro supports strings with the simple form <code>&quot;string&quot;</code>, which is superficially cleaner than the Forth <code>.&quot; string&quot;</code>, where the spacemark is important. I actually prefer the latter, which enforces a Forth convention that spaces always trail. Anyone who has dealt with two different assumptions about where spaces belong can feel me on this one, I hope. Similarly, cr/nl is always prefix. These are good conventions. If you need leading whitespace in a string frequently, first: consider that you might actually need trailing whitespace and second, write a word for it. It&#39;s an interesting challenge, try it! </p>

<p>There&#39;s a more subtle problem. The Forth interpreter does this: <code>word? number? if succeed else fail then</code>. Retro has to try <code>string? word? number?</code>; I don&#39;t like anything that breaks the power to redefine a word. Even the absurdity <code>: 1 2 ;</code> is a consequent with value; consider a special vocabulary containing <code>: 10 [char] A ;</code>. Or <code>: 10 10 select.window</code>, which keeps the number <code>10</code> around for just long enough to make the definition. </p>

<p>This imaginary modular forth would try <code>word? module-word? number?</code>, meaning a redefinition of <code>word.:book</code> would block <code>word</code> in the <code>book</code> module. The compiler should complain about any word that contains <code>.:</code>, and be loud about if that word actually blocks a module word. This is better than the user complaining because they need the ability to make a word containing <code>.:</code> for whatever reason, and the compiler won&#39;t let them. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Vanguard Generation]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/26/the-vanguard-generation/"/>
    <updated>2014-01-26T14:26:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/26/the-vanguard-generation</id>
    <content type="html"><![CDATA[<p>There is a small but significant group tucked between Generation X and the Millenials. As a member of that generation, it seemed worth pointing us out.</p>

<p>The 20th century may be sharply divided into eras by the chief inventions: the internal combustion engine, nuclear weapons, and the computer network. I could say &quot;computer&quot;, just as one could make a case that the middle technology was the television. But it wasn&#39;t computer which changed us, it was computers, wired together.</p>

<p>The Vanguard generation, in 2014, are clustered between the ages of 30 and 40. In 1994, we were 10 to 20 years old. Simply put, we remember life without the Internet, but learned it during puberty. </p>

<p>There are plenty of people ten or twenty years older who found the Internet in their all-important adolescence. The university experience in America delays adolescence, with the (usually unrecognized) upside of longer plasticity for learning among the inclined, so there are a few Avant Vanguardists. Reduplication and elision, yay! They do not a generation make. </p>

<p>More importantly, they suffered through the September than Never Ended. Their Internet was not our Internet: we are the Vandals and Visigoths who wrecked their kingdom. Sorry about that. Did I mention we were going through puberty? </p>

<p>The Millenials are fish in water. They have never heard an adult ask another &quot;Do you have email?&quot;, only &quot;What&#39;s your email address?&quot;. And so on, and so forth, for all of it. </p>

<p>In the present, the Baby Boomers rule, and Generation X runs it. Soon, Generation X will rule, and the Vanguard will run it; this is the way of the world. </p>

<p>By that time, our very biological existence will rest on the network. It already does, but we have only begun to reap the harvest of internal combustion and all that it brought. In a very real way, the Internet or its heir will rule us, and that&#39;s the optimistic scenario. </p>

<p>To the Vanguard I say this: Keep your memories of the nascent Network. Remember the floppy, and what fits on it. Cherish the freedom of your youth, when, lacking a cell phone, you had to find your friends a terra and your parents had to yell or call around. </p>

<p>More: Understand that our teetering, broken, stringy technology stack was written by Boomers, mostly, and other people who didn&#39;t know any better. Charitably, the technology wasn&#39;t mature, though the luminaries and prophets of the era would vigorously disagree. We&#39;re inheriting it, along with the pride of a lifetime&#39;s work; rather than take it behind the barn and shoot it, let&#39;s gently put it out to pasture and emulation. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Literal and Figurative Languages]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/24/literal-and-figurative-languages/"/>
    <updated>2014-01-24T12:12:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/24/literal-and-figurative-languages</id>
    <content type="html"><![CDATA[<p>Axiom: there are no clean separations between programming languages.</p>

<p>Corrolary: if one can be found, someone will design a language specifically to blur the resulting boundary.</p>

<p>The terms high and low level languages are frequently bandied about. If your word of code stretches from Python to C, these are comfortable categories, with room for interesting bikeshed debates on the margins. </p>

<p>At one time, this almost made sense. Languages were either properly interpreted from strings, or compiled into genuine code. Even in those hoary days there were vigorous communities, notably Lisp, Smalltalk and Forth, where these distinctions were blurred or simply did not apply. </p>

<p>This is no longer even vaguely how things work. On the one hand, most interpreted languages are compiled to a bytecode, and many are further optimized from there. LuaJIT in particular can demonstrate superior performance over compiled languages in certain circumstances, in particular cases where the input to a functional cascade can rapidly change character. JIT compilers can keep up with this, while a static compiler by definition cannot optimize for data the program it&#39;s compiling hasn&#39;t seen yet. </p>

<p>One the other side, which I feel is less known, we have OpenCL. This is a decidedly low-level dialect of C, in which pointers are not allowed and &#39;functions&#39; are syntax to allow inlining of code. This is compiled and optimized into multiple dialects (CPU and any available GPUs), on the fly, from strings. A running OpenCL program makes some of the fastest machine code possible from strings in the runtime environment.</p>

<p>Clearly this distinction has completely collapsed. The more interesting division is between literal and figurative languages.</p>

<h2 id="toc_64">What This is Not</h2>

<p>The distinction is not between static and dynamic, nor is it about performance or degree of interactivity. I can happily find orthogonal examples of all of these in both the literal and figurative family.</p>

<p>The distinction is this: a literal language abstracts the hardware, while a figurative language abstracts a problem domain. </p>

<p>Assembly is of course literal, along with Forth and C. Haskell is highly figurative, while the Lisps tend to blur the line in interesting ways: within only Scheme, Racket has a layer that is more hardware oriented, while Chicken delegates this aspect to C. SBCL can dig down as deep as you want, but Lisps in general are figurative in emphasis: invisible garbage collection is a figurative pattern and a pillar of Lisp programming. Despite this, the garbage collector itself has occasionally been written in Lisp. I confess I have trouble understand how this is done; low level Lisp is almost a different language. </p>

<p>Hoon is an interesting case. We think of Nock as a sort of Hermetic seal; above the Nock layer, Hoon is straighforwardly literal. This is not uncommon; Retro, a Forth dialect, targets a very simple virtual machine that is quite literal on the target architectures. Lua is more figurative, but it&#39;s a brisk afternoon&#39;s work to discover how the virtual machine works and how to target it from C, Lua&#39;s home environment. </p>

<p>This intersects with compactness in some ways but not others. Assembly, our most literal, is as complex as the architecture, which has gotten truly gnarly on our flagship systems. </p>

<p>I&#39;m doubling down on Forth because it combines a low mental surface area, a literal machine model, interactivity, and introspection. The &#39;word&#39; is a strangely powerful abstraction. If you want (and I do) a colorful, interactive environment for exploratory systems programming on existing chips, Forth is the natural place to start. If only it had a nice, modern type system&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[There is no Garbage]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/17/there-is-no-garbage/"/>
    <updated>2014-01-17T13:02:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/17/there-is-no-garbage</id>
    <content type="html"><![CDATA[<p>Garbage collection is another solution to a problem we don&#39;t have.</p>

<p>Here&#39;s my system: 4 cores, 8 GiB ram, 256 GiB flash store, 2 TiB off-deck backup. 64 GiB on the phone, 128 GiB on the tablet; I&#39;m a packrat by nature. </p>

<p>I have garbage collection why, again? Because no one has written software around this unbelievably roomy environment.</p>

<h3 id="toc_51">&quot;But&#8230; what if I have an arbitrary amount of data to process?&quot;</h3>

<p>What, like in a file?</p>

<h4 id="toc_52">Sure&#8230;</h4>

<p>Couldn&#39;t you allocate some memory for the file and copy it over?</p>

<h4 id="toc_53">That&#39;s slow with a huge file.</h4>

<p>No, <strong>reading</strong> it is slow with a huge file. Allocating it is free.</p>

<p>You could also, maybe, make the files a little smaller? The user never has to know, though it&#39;s polite to tell her if she asks.</p>

<h4 id="toc_54">What if I run out?</h4>

<p>What, of the huge chunks of imaginary allocated memory? Close a &quot;file&quot; by forgetting it ever happened.</p>

<h4 id="toc_55">What if I changed something in the file&#39;s contents that I wanted to keep?</h4>

<p>And you didn&#39;t make a copy to the store immediately? Are you five?</p>

<h4 id="toc_56">I didn&#39;t know if it was a good change or not</h4>

<p>&#8230;you&#39;re five. I said &quot;copy&quot;, not &quot;destructive update&quot;. </p>

<h4 id="toc_57">Okay hotshot, what if it&#39;s arbitrary data from a socket?</h4>

<p>Me, I&#39;d be writing it to the store, hoss. Then, it&#39;s a file. Allocate more than you can store or process and start using it. </p>

<p>Take notes. Store them. Perhaps even ask the other computer first how much data it&#39;s sending. This is legitimately not always an answerable question, and sensors provide numbers too. </p>

<h4 id="toc_58">What about huge transients from my enormous calculations?</h4>

<p>&#8230;you were dynamically allocating huge transients in enormous calculations?</p>

<p>I can hear that server farm humming from here. You. Had. One. Job.</p>

<h4 id="toc_59">But I just want an array, and I don&#39;t know how much to put in it, and I won&#39;t need it for long, and&#8230;</h4>

<p>No, you are wrong about all of that. You want a proper functional shared memory data structure, to which two things are done:</p>

<p>They are created and</p>

<p>They are durably written to main store.</p>

<p>Unless they&#39;re, uh, huge transients. Y&#39;know, like the fake Intel computer asm.js makes for you. Dynamically, wink wink, say no more. &quot;wait, that&#39;s.. that&#39;s an array of&#8230;&quot;. That&#39;s no moon, friend. </p>

<h4 id="toc_60">Look, I have really complex, relational data relationships, that I have to query and then get results of variable size back.</h4>

<p>That sounds like you want some kind of &quot;base&quot; for &quot;data&quot;. Perhaps someone has written one, and it can handle your requirements.</p>

<p>Which sound kind of special. Perhaps you want a dedicated chunk of hardware? It could &#39;serve&#39; you this data. Now, you have arbitrary data from a socket to allocate. </p>

<p>There are two kinds of bases for data: those in which there is a type of request which always, without exception, returns the same data, every time, and those which are enormously useless and must be scrapped in favor of something you can use.</p>

<p>This is also true if you call your &quot;data base&quot; a &quot;web site&quot;, as it happens.</p>

<p>If you have the former, you: request data be delivered in fixed chunks, process it, remember the <em>request</em>, save the <em>result</em>, and anything else may be immediately and comfortably forgotten.</p>

<h4 id="toc_61">&#8230;lisp</h4>

<p>I can&#39;t help you there, at the moment.</p>

<h4 id="toc_62">You are significantly underestimating the complexity of a modern operating system.</h4>

<p>I have enough room in RAM to load a DVD and watch the entire thing.</p>

<h4 id="toc_63">You cannot eliminate garbage without abandoning Unix.</h4>

<p>Happily, Unix now comes on Flash USB drives, with costs similar to a cheap night out wherever the hacker is found in native habitat. </p>

<p>Fusing this to the motherboard is not a hard problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concurrency Is An Artifact]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/17/concurrency-is-an-artifact/"/>
    <updated>2014-01-17T11:59:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/17/concurrency-is-an-artifact</id>
    <content type="html"><![CDATA[<p>Your concurrency problems are a direct consequence of your software architecture. </p>

<p>Concurrency is a consequence of carrying a solution forward without remembering what it&#39;s trying to solve.</p>

<p>Preemptive multitasking is a weird thing to do: you interrupt the computer, with its permission, do something else, then it goes back to what it&#39;s doing. There&#39;s all sorts of complex negotiations; the good news is, it works, usually. </p>

<p>This is a solution to a hard problem: how to do a bunch of things with only one CPU.</p>

<p>So I&#39;m guessing you have 4 CPUs, which makes the architecture fundamentally asisine. </p>

<p>All your concurrency problems stem from this. Do hypervisors have concurrency problems? Wouldn&#39;t know; bet they don&#39;t, because they sensibly allocate processors and memory. </p>

<p>If you took a systems architect from a more sensible time, the 1970s say, and gave them a decent AMD chip, they would first go for a walk with a beer and a tab of acid to consider the implications. They would proceed to write something entirely different from what you have.</p>

<p>It would be entirely based on the idea that they have 4, let&#39;s say, supercomputers of unfathomable power, hooked up to more core memory than they can understand, attached to store counted in units they have never seen before, except in jest.</p>

<p>Would it emulate Unix? Would it create a master control program that emulates multiple Unices?</p>

<p>No. This is not what it would do, at all.</p>

<p>It used to be standard practice to rearchitect systems in light of new capabilities. This stopped because of two autistic people with different fixations: Bill Gates and Richard Stallman. My esteem for both men is considerable, in light of the former&#39;s philanthropy and the latter&#39;s stubborn and correct fixation on the privacy and freedom implications of open source systems. </p>

<p>They share a fatal obsession: backward compatibility. Stallman, in particular, has an almost detestable belief that software should be written once and for all. Imagine an artist with the same attitude to painting, or the novel; we would deride them as the martinet that RMS often presents.</p>

<p>There are other, better options: keep the old beasts running, rewrite for new systems, or wait around for awhile until speed gains mean you can emulate. Unix has been under emulation for quite some time.</p>

<p>We have two tricks: speed gains, and writing new software. And we appear to be fresh out of bubblegum.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Those Dadgum Adders]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/12/those-dadgum-adders/"/>
    <updated>2014-01-12T15:05:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/12/those-dadgum-adders</id>
    <content type="html"><![CDATA[<p>I read <a href="http://prog21.dadgum.com/33.html">a description of Forth</a> years ago, that stuck with me.</p>

<p>Now that I&#39;m writing some, let&#39;s try this problem out. The premise: given three arrays of three integers, add x and y, putting the result in z. In C, this is easy by design. </p>

<p>Oh, and array overflows have probably cost us a trillion dollars by now. Kudos!</p>

<h2 id="toc_49">Forth is factoring</h2>

<p>First, no custom data types, but lets actually define and fill two &#39;arrays&#39;.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>variable foo[] 2 cells allot
</span><span class='line'>variable bar[] 2 cells allot
</span><span class='line'>variable baz[] 2 cells allot
</span><span class='line'>
</span><span class='line'>99 99 99 foo[] ! foo[] cell + ! foo[] 2 cells + !
</span><span class='line'>2 4 8    bar[] ! bar[] cell + ! bar[] 2 cells + !
</span><span class='line'>16 32 64 baz[] ! baz[] cell + ! baz[] 2 cells + !
</span></code></pre></td></tr></table></div></figure>

<p>This is wordy. Wordier than it needs to be. But also easy to read. Notably, we do not juggle the stack; it&#39;s somewhat bad form while interpreting. </p>

<p>Clearly if we need a lot of arrays, we&#39;ll define something to handle them. Which kind of array do you need?</p>

<p>Today, like the problem, we need a C array: stupid, unbounded, and untyped. </p>

<p>Now we need a word to add the values of three addresses together.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>: add-advance  \ ( a1 a2 a3 -- a1+ a2+ a3+ )
</span><span class='line'>  \ &quot;add a2 and a3, store value in a1. Advance all three addresses.&quot;
</span><span class='line'>  dup&gt;r -rot dup&gt;r -rot dup&gt;r -rot \ ( a1 a2 a3 -|- a1 a2 a3 )
</span><span class='line'>  @ swap @ +                          \ ( a1 a2+a3 -|- a1 a2 a3 )
</span><span class='line'>  swap !                              \ ( nil -|- a1 a2 a3      )
</span><span class='line'>  r&gt; r&gt; r&gt;                            \ ( a1 a2 a3    --        )
</span><span class='line'>  cell + rot cell + rot cell + rot    \ ( a1+ a2+ a3+ --        )
</span><span class='line'>  ;
</span></code></pre></td></tr></table></div></figure>

<p>Line by line, shall we?</p>

<p><code>dup &gt;r -rot dup &gt;r -rot dup &gt;r -rot</code> puts a copy of every address on the return stack for later. I&#39;d call this <code>punt</code> if I planned to do it frequently. </p>

<p><code>@ swap @ +</code> takes the values from the two address and adds them together, while <code>swap !</code> saves the result to <code>a1</code>. </p>

<p><code>r&gt; r&gt; r&gt;</code> is the anti-punt, basically. We could do the <code>cell +</code> call inline with it, but I feel this way is clearer: the <code>cell + rot cell + rot cell + rot</code> adds one cell width to each address, advancing it. </p>

<p>So far so good. Let&#39;s make a word that creates a word that adds an array of n. </p>

<p>Wait what?</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>: n-adder \ ( create: n -&gt; nil does&gt;: &#39;add-advance&#39; )
</span><span class='line'>  create ,
</span><span class='line'>  does&gt;
</span><span class='line'>  @ 0 do add-advance loop
</span><span class='line'>  drop 2drop ;
</span><span class='line'>3 n-adder 3-adder
</span></code></pre></td></tr></table></div></figure>

<p>Looks like we solved the problem for, not array[3], but array[n], for any n. Of course, we have to make a new word each time. <code>here</code>, <code>allot</code> and <code>:noname</code> can be combined to the same thing in anonymous ways. This is strictly speaking over general; we add an entire extra line of code, and one additional word, in the pursuit of perfect generality. </p>

<p><code>:noname create , does&gt; @ ( ... ) ; 3 swap execute 3-adder</code> would make our adder without providing further capability.  </p>

<p>Just as clearly, we could make a word that generates an array of n, and stashes n as the first value of that array. Then we could make a bounds checked version. It could even add two arrays of unequal length into an array equal or larger than the both, though we would need to define each behavior fairly carefully. </p>

<p>Or we could make a creator word that takes any other word that acts on the values of three addresses, and applies that word to an array of arbitrary length. There&#39;s plenty of room in a 64 bit offset for a type system for the resulting array; we could end up with a <code>+</code> (pre|post|in) fixing (two|three) arrays of arbitrary type and length, if that was useful. Depends on the language you want.</p>

<p>The reason Forth doesn&#39;t provide the C array structure is because it doesn&#39;t presume to make that choice for you. Simple as that. </p>

<h3 id="toc_50">Footnote</h3>

<p>Astute Forth heads might find this one weird: <code>\ ( a1 a2 a3 -|- a1 a2 a3 )</code>. That <code>-|-</code> is an annotation I call the mirror: the return stack runs backwards from the data stack: <code>a b c -- &#39;&gt;r &gt;r&#39; -&gt; a -|- b c</code>.</p>

<p>It&#39;s easy to read, and clear. I use <code>--</code> to show that a stack annotation is completed and <code>-&gt;</code> to show a stack change, normally in a colon definition. It&#39;s so regular a computer could almost do it. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Simple Closure in Forth]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/12/a-simple-closure-in-forth/"/>
    <updated>2014-01-12T12:28:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/12/a-simple-closure-in-forth</id>
    <content type="html"><![CDATA[<p>Forth is what you make out of it. If you want a structure or language artifact, and you understand what it does, you may create it.</p>

<p>Let&#39;s write a simple closure in Forth.</p>

<h2 id="toc_48">Simple Closure</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>\ Rollhex
</span><span class='line'>
</span><span class='line'>: offset-hexpr \ ( offset n -- new-offset )
</span><span class='line'>   tuck                            \ ( n offset n -- )
</span><span class='line'>   hex 0 do                        \ ( n -- `hex`    )
</span><span class='line'>      dup i + 16 mod               \ ( n n+i%16 --   )
</span><span class='line'>      dup 15 &lt;&gt; if                 \ ( n n2     --   )
</span><span class='line'>          0 &lt;# # #&gt; type           \ ( n -- "n2"     )
</span><span class='line'>      else \ red F
</span><span class='line'>          0 &lt;# .#! # .#r #&gt; type     \ ( n -- "n2"     )
</span><span class='line'>      then
</span><span class='line'>   loop decimal                    \ ( n -- `decimal` ) 
</span><span class='line'>   + 16 mod                        \ ( new-offset --  )
</span><span class='line'>   ;
</span><span class='line'>
</span><span class='line'>: hexer  \ ( C: nil -&gt; nil D: nil -&gt; nil "hex" )
</span><span class='line'>      create \ ( nil -&gt; nil )
</span><span class='line'>          0 ,
</span><span class='line'>      does&gt;  \ ( nil -&gt; nil )
</span><span class='line'>      dup &gt;r @ swap offset-hexpr r&gt; ! ;
</span><span class='line'>
</span><span class='line'>hexer rollhex </span></code></pre></td></tr></table></div></figure>
  

<p>A call such as <code>2 rollhex</code> will produce <code>01</code> as output. <code>2 rollhex</code> again produces <code>23</code> and so on. We highlight each <code>F</code> in red. </p>

<p>This is a small utility, kind of like a measuring tape for a terminal. You can repeatedly fire it at a rectangle of text, and get a quick count for how many characters you&#39;ve printed. There&#39;s no need for a reset word, you can call <code>0 &#39; rollhex !</code> or whatever new value you want the closure to have. Literally, this puts 0 on the stack, puts the address of rollhex on the stack, then stores 0 to the address, just like we did when we <code>create</code>d it.</p>

<p>Could you embed this in some kind of &quot;object&quot;? Certainly, and you do so in the same fashion: by rolling the behavior you want, directly. If it gets moderately complex, you use access words. And so on. </p>

<p>This is dramatically over-commented Forth. Almost every comment is wrapped in an outer comment. The result looks weirdly like some kind of annotative type system operating in parallel with the Forth. In fact, it is, this is how Forth programmers keep track of programs. In their head, with a yellow legal notepad nearby. </p>

<p>You&#39;ll note the famous &#39;stack juggling&#39;. Stack juggling is to Forth as the parenthesis is to Lisp. The issue with Forth is not on the left side of the source code; the issue is that the right side exists, at present, only in our minds. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[State of Forth, 2014]]></title>
    <link href="http://mnemnion.github.io/blog/2014/01/08/state-of-forth/"/>
    <updated>2014-01-08T13:45:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2014/01/08/state-of-forth</id>
    <content type="html"><![CDATA[<p>I had a <a href="http://www.loper-os.org/?p=1390#comments">very interesting conversation</a> with Loper recently about, well, superficially it was about Urbit. </p>

<p>It came at an interesting time, as I was rewriting <a href="http://mnemnion.github.io/ax/spec.html">Ax</a> in Forth. That&#39;s a done deal, but I&#39;ve temporarily lost interest. As an aside, the Ax inner loop calls for roughly ten basic Forth words, the kind that are normally one to five machine instructions long. That is&#8230;not insolubly slow, even on hardware that&#39;s somewhat hostile to the level of indirection involved in a noun.</p>

<p>Forth itself has seized and held my attention. </p>

<p>I remain convinced that Urbit, or something like it, must be built and must be built now. I hope for efficiency&#39;s sake that <a href="http://tlon.io">Tlon</a> will be the ones to do it. </p>

<p>Similarly, the things <a href="http://www.loper-os.org/?p=1427">Loper</a> is up to right now are totally right on, and frankly, the sooner the world gets Loper designed hardware the better off we&#39;ll be. </p>

<p>And then I started learning the Way of Forth. People have the wrong idea about Forth, because they think it&#39;s a language, when it&#39;s actually a programmable program. Now, every language runs on a programmable program, but Forth <strong>is</strong> a programmable program, and therein lies the difference. </p>

<h2 id="toc_45">Tame the Beast</h2>

<p>Forth is in danger of becoming a lost art. Few of the younger generation are learning the way. It survives in a surprising number of contexts, far away from the mainstream of open-source, Unix and network-oriented software. Most Forth users are using commercial Forth environments that they paid for. </p>

<p>This is easy to explain: Forth, the language, has almost nothing to offer. Viewed as a language, it&#39;s more than just primitive, it&#39;s barbaric. </p>

<p>Then you go to write something like an assembler, and realize that Forth is dramatically the best language for that job. Seriously, <a href="http://krue.net/avr/">check this out</a>. This is the best assembler you&#39;ve ever seen. Go find a C assembler if you don&#39;t believe me. </p>

<p>The version of this that runs on the microcontroller, in a <a href="http://krue.net/avrforth/">native Forth environment</a>, lets you interactively design assembler words and test them, on the microcontroller itself. Y&#39;know, no big deal, I bet you do that all the time.</p>

<p>It&#39;s been said there are more Forth implementations than serious systems written in Forth. This is actually untrue to the verge of slander, but Forth is meant to be hand-rolled to the task. It is a <a href="http://www.colorforth.com/POL.htm">problem oriented language</a>. By the way, if you haven&#39;t read POL, I insist. It is a fundamental work of computer science; Chuck was a student of McCarthy at the dawn of Lisp.</p>

<p>The way of Forth is to take the target architecture and tame it into a consistent environment for getting things done. The stack abstraction may always be applied, and normally at a cost similar to a subroutine-call environment. </p>

<p>I have my notions of what&#39;s driven Forth into its present, moribund state. It&#39;s mostly ANS, which abstracts the machine away in the name of portability. This renders Forth a weird concatenative abstract language, taking away its numerous advantages. The C standard is far more literal and close to the hardware than the Forth standard, and this causes the latter `language to suffer immensely. </p>

<p>It remains the best machine tool in the arsenal. If the job is taming a wild chip, Forth is your friend. It&#39;s the best way to punch down, period, and with some support, I can picture it punching up with the best of them.</p>

<p>How to write a post-C environment using existing high-calibre ARMs and possibly Intels? Forth alone will not suffice. But if we stick with <a href="http://en.wikipedia.org/wiki/Atmel_AVR">AVR</a> for a bit, then gun for modest 32 bit ARM systems, we may discover that the big iron is obsolete. It&#39;s also quite possibly dangerous: there may be Balrogs built into the big chips, and certainly, the board architecture we&#39;re using is not nearly paranoid enough. </p>

<h2 id="toc_46">Interactive Enlightenment</h2>

<p>I don&#39;t dislike writing C. I learned it when my brain was fairly plastic, so despite the rust, I can get &#39;er done. I have always despised debugging it. GCC is pain, mostly concealed with make, though make is also pain when you have to write it. GDB is pain multiplied by pain. I cut my teeth on Turbo Pascal, and this shit <em>hurts</em>. The only saving grace of Java is that stepping though that garbage is of necessity well-tooled. C programmers are masochists, to the last one; they not only invented Hungarian, they frequently use it. </p>

<p>C engages in premature optimization, which is known to be the root of all evil. It won anyway, because Forth provides no way to hand off any programmer discipline to the compiler, and efforts to add them have failed spectacularly. I have a notion, but code speaks and I have a lot to learn. </p>

<p>There&#39;s also the fact that C is Algolic. Algol was designed so the pseudo-code programmers developed ad-hoc could be used to write real programs. It&#39;s no wonder that a language driven (that&#39;s human language, specifically Western European) design became effective and popular. It&#39;s taken decades to learn that the pain of compiling Algol puts an enormous burden on systems programming; indeed, this lesson has yet to catch on.</p>

<p>Nonetheless, let me state a law: If a system does not provide an Algol, it will fail. Dialect matters less than you think it does, but there are no downsides in using something sensible with a decent user base. Lua, say. Lua is a nice Algol. </p>

<p>I plan to write a nice, Unix hosted system that provides a roomy, enhanced window into the running environment of a second computer. This treats Unix like the fancy terminal it is, giving us the all-important ability to code and use the Internet at the same time. </p>

<p>The only Forth that is even skeletally complete, from a Unix perspective, is gforth. That&#39;s a GNU tool, making the code pure contagious poison that can never be used for anything. Unfortunately pforth, the public domain version, is missing certain essential ANSI term handling words, so I&#39;m using gforth for now. </p>

<p>The program, provisionally called Forge, may be thought of as a cockpit for piloting a Forth system. Self-introspective, yes, but built primarily to operate an umbilical Forth environment on a remote platform. We may use this comfortable tool to make compact, excellent microcontrollers which can talk to each other and host systems; the wisdom gained may be applied to writing a better host Forth, and then we&#39;re in business.</p>

<p>Forge is intended for interactive systems programming. Building out an operating system requires a lot of scaffolding, and there are self-reference problems with trying to host that scaffolding on the system you&#39;re assembling. </p>

<p>I mean enlightenment in the sense of shining a light. Compiled C code is dank, obscure, and our current architectures further convolute the actual execution of code. There have been benefits, but the tradeoff isn&#39;t worth it: what you cannot see, you cannot understand without great strain. Show me a tool for interactive physical inspection of the hardware state. Show me how to write it in C. If you know the language, you know the problem: all the information you need is simply gone, and there&#39;s no good way to get it back. </p>

<p>Astute coders can do terrifying things with stack machine optimization. LUAJit and HotSpot are works of pure magic. The fact that this has not been effectively combined with Forth in an open-source tool is part accident, and part missing type information. </p>

<p>Oddly enough, Forth programmers provide type information, in the form of comments. All good code has them. Nothing in the computer reads these annotations or does anything useful with them. We&#39;ll get back to this thought, but not today.  </p>

<h3 id="toc_47">The Way</h3>

<p>Forth is a Daoist, immediate, personal approach to the computer. I have some problems, that are conceptually large. I intend to write and rewrite those problems until I have some good languages for solving them. </p>

<p>This post was going to be a survey of the Forth ecosystem; perhaps later. Instead, I&#39;ll end with meditation.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>If the System provides garbage collection,
</span><span class='line'>the Language cannot write one.
</span><span class='line'>If the System provides syntax,
</span><span class='line'>the Language must use it.
</span><span class='line'>If the System provides types, 
</span><span class='line'>the Language shall have them.
</span><span class='line'>Doing less,
</span><span class='line'>Presuming nothing,
</span><span class='line'>Staying empty,
</span><span class='line'>The Way of Forth
</span><span class='line'>Provides the Language,
</span><span class='line'>Enables the User,
</span><span class='line'>To Build the System
</span><span class='line'>In Accordance with the Way.</span></code></pre></td></tr></table></div></figure>

<p>Back to the metal. More later.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Commentary on Ax]]></title>
    <link href="http://mnemnion.github.io/blog/2013/12/19/commentary-on-ax/"/>
    <updated>2013-12-19T10:14:00-08:00</updated>
    <id>http://mnemnion.github.io/blog/2013/12/19/commentary-on-ax</id>
    <content type="html"><![CDATA[<p>Ax has been <a href="http://mnemnion.github.io/ax/spec.html">written</a> and implemented, twice. A bit of orientation is in order. Today&#39;s post will be as computerific as possible; we&#39;ll dig down into the deeper &#39;why&#39; in later parts. This may take awhile.</p>

<h2 id="toc_29">Preface</h2>

<p>There are 720 valid <a href="http://www.urbit.org/2013/08/22/Chapter-2-nock.html">Nock machines</a>, defined as any cellar automaton which provides a mapping from the Nock rewrite rules to any one of every digit of set {0..5}. Since one of them is actually called Nock, let&#39;s call the permutation group Conk. </p>

<p>2 of them are Ax machines, or would be, minus the <code>fz</code> operation. That is, there are 2 Conks which have the same mappings for <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>. There are actually 6 Ax machines, 2 of which have the same axioms as Nock machines; we may consider those two as Nock equivalent, by permuting <code>fz</code> above the Nock (proper) threshold of 10. By the same simple mathematics, there are 5040 possible Conk-compliant machines computationally equivalent to Ax, Nock not among them. We will call this permutation group Xa, for what other choice do we have? </p>

<p>6 is a small enough number to consider in entirety. The only bit that is arbirary is the range on sigma, which is only arbirary if you&#39;re not an extant silicon computer. </p>

<p>I am convinced Ax α is the best possible choice among the 6. I hope to demonstrate that here. </p>

<p>There are an infinite number of cellular automata. Conk machines are a class. Ax machines are an interesting subclass, disjoint by one member. </p>

<h2 id="toc_30">Rationale.</h2>

<p>Ax is even weirder than Nock, because it never terminates. In order to calculate Ax, you must use a certain amount of judgement. </p>

<p>Ax is recursively self defined. Absolutely every valid rewrite may be performed, in a metacircular fashion, and the expansions are defined in terms of each other as well as the reduction. As in Go, you must apply the Ko rule to infinite loops: if you may continue to play, you should continue to play.</p>

<p>A trivial loop, such as Ξ [a] -&gt; Ξ [a], is like a game where the only remaining moves are Ko. The polite thing is to pass and count the board. In Ax, as in Nock, this is our only form of error. </p>

<p>Note that detecting all cases of Ko without arbitrary calculation is of course the halting problem. In practice, an Ax interpreter may be made into a Nock interpreter by dispatching on a subset of the operators. </p>

<p>Since you need the idioms, particularly <code>if</code>, to define many of the fundamental operators, the expansions are the second set of statements, after the definition. The definition says what the operators do, the expansions say how they could do it, given the available operators, and the ability to decide when you&#39;re tired and quit. </p>

<p>It would be nice, and is probably inevitable, if all the non-trivial operations are visited within an expansion of 0. That way, you can type [0 0 0] into the reference Ax machine and it will not only run forever but repeatedly visit all definitions in doing so. </p>

<p>Since a decent expansion of 0 would could be Ξ [a 0 b] -&gt; Ξ [[b a] 2 2] we should be good to go.</p>

<p>Oh the reference implementation? Scheme, of course. It is incapable of returning, though you&#39;re welcome to make a few changes if you want to see it do something. It does this in the best continuation passing style! Not that it exists. Instead, we have a demo machine in Lua.</p>

<h2 id="toc_31">The Preamble</h2>

<p>Compared to the Nock spec, this is enormous and pedantic. Compared to a representative work in the genre, it is haiku.</p>

<p>Xa space being a permutative superset of Conk space, the Ax preamble contains the Nock preamble, in its entirety, without modification.</p>

<p>Which is a marvel, by the way. Every time I&#39;ve sniffed out an ambiguity or source of confusion, I have been wrong. Even lines six and seven may not be made to malfunction, despite strict operator overloading. Try it.</p>

<p>It is overloading, however. [1 + a] would be [[1] +*[a]], and *a crashes. But it doesn&#39;t say [1 + a], does it.</p>

<p>Arguably, our symbol definitions, despite being English, are equivalent to the pseudocode. And indeed our generalized rules, being only one reduction longer, are shorter, line for line,  than the pseudocode plus the reductions. Not counting brackets, Nock uses seven symbols, overloads one, and has four variables. We use six symbols, no overloading, five variables, and need an extra symbol to define our extra operator. </p>

<p>We also have the expansions, or will. Which I feel add a certain esprit to the spec. </p>

<p>It is a little confusing, if conventional, that &#39;a&#39; is either an atom or a cell, while &#39;n&#39; is definitely an atom and definitely not the other sort of noun. I trust the reader to follow along, and using &quot;a&quot; for atom and &quot;b c d e&quot;, while cool, would add impedence to both understanding the Ax spec per se and comparing it to the Nock spec. </p>

<p>It&#39;s not so bad, really. We also need an additional clarification that partial expansions of a line are not allowed. </p>

<h2 id="toc_32">Mythos.</h2>

<p>So here&#39;s how you read Ax. You&#39;ve been captivated by alien intelligence, who have sat you down in front of something suspiciously resembling a vintage VT100 terminal. You receive the preamble, and the term. The cursor blinks.</p>

<p>There doesn&#39;t appear to be any way out of this&#8230;pod, Tardis, what have you. Though it is made up in a somewhat surreal and misguided parody of human habitation, you&#39;re not sure that the fruit is edible, and don&#39;t want to find out. </p>

<p>Well, what would you type? You&#39;re not a chump, if they wanted to use your letters they&#39;d speak your language. Plus, they just told you &quot;numbers&quot;. Practically shouted it. </p>

<p>So you type zero, and get an infinite loop. Let&#39;s try a cell of zeros: nope, crashes. Well, a cell can be composed into two cells and ok, we have a zero back.</p>

<p>Which one did it return? You could just bang away at the keys but this is a delicate operation. [0 1 0] is an infinite loop, [1 0 0] produces 0, [0 0 1] produces..one. Can we do anything else coherent with ones and zeroes? </p>

<p>It appears we can: [0 1 0 0] produces 1 also, but for what reason? A bit of experimentation discovers that [0 1 0 1] produces the all important 2. We can in principle make any number now, which is nice, but still feels a bit like cheating, because we&#39;re using the command line, not the computer. [0 1 0 1 0 1] is a syntax error, but [1 0 1 0] produces&#8230; [1 0]. Interesting, but reductive, though serving to confirm what we might already suspect. </p>

<p>On a hunch, you type [2 1 2 1]. The screen fills with endless columns of cellular numeric data, prettily colored, and looping in a way that looks alarmingly like a refutation of the problem with halting. It then halts, executes an impressive screen fade quite impossible on a real VT100, and then helpfully types [2 1 2 1] for you once more. This time, it simply returns 3.</p>

<p>Everything else you need to know is in the guts of the core dump. Congratulations, space cadet. &lt;3 &lt;3 !</p>

<p>You may notice that in Ax, trees are built up from numbers. The feeling is one of open-ended discovery. The computation branches out fractally, resolves itself in some mysterious way at the limit, and returns a form. A fundamental axiom guarantees non-deterministic behavior. In Nock, numbers are derived from nouns, choices are absolute, and your result is either error or truth.</p>

<h2 id="toc_33">Axioms</h2>

<h3 id="toc_34">Zero</h3>

<p><code>0</code> is the identity operator, <code>is</code>. There are two operations that are closed over the monoid of the natural numbers, addition and multiplication. Of them, multiplication is consequent. In the operation of addition, 0 returns the identity. If you have any number, you may now return it. You now have <code>0</code>, and may return it: Ξ [0 0 0] -&gt; 0</p>

<h3 id="toc_35">One</h3>

<p><code>1</code> is the increment operator, <code>up</code>, as premised in the preamble. If you have a number, and you now have 0, you may increment it. Ξ [0 0 1 0] -&gt; 1</p>

<h3 id="toc_36">Two</h3>

<p><code>2</code> is the branch operator, <code>br</code>. I like slot, but we normally call those branches, and I count six English pronunciations for <code>slt</code>, one of them distasteful. You need <code>0</code>, <code>1</code>, <code>2</code> and <code>3</code> to define <code>br</code>, but you can use <code>1</code> and <code>2</code> to produce 3. <code>mod</code> being explicitly provided, we may write an expansion that actually runs quite servicably. The Nock spec provides no way to factor <code>a</code> into <code>a + a</code>, nor to determine which of lines 15 or 16 to apply. This does not detract from its correctnesss, these are very ordinary operations on the <code>natural number</code>s.</p>

<p>Branch <em>selects</em> a branch, it does not <em>cause</em> one. Branch/forking happens in the same two ways in Ax as in Nock, because Ax is a Nock machine. Note that <code>br</code> on branch <code>0</code> (to apply <code>br</code> is to &#39;graft&#39; the subject and return a branch from it) is not a syntax error, but rather, undefined. It may be a syntax error if you wish, or produce a noun, which is a common anticipated use. It may even produce an effect, but that would be crazy. The spec doesn&#39;t say, though; grafting on zero means your code is not deterministic. Crashing is the best idea if you don&#39;t know what else to do. </p>

<p>Note that so far, we have halting rules and trivial crashes only. Next comes the distribution rule, which gets us most of the way there,<br>
and then the explicit recursion rule, <code>ax</code>. These <strong>cause</strong> branches, and composing that ability with <code>br</code> raises the bar. </p>

<p>How many operators does it take to write an infinite loop? I am curious, without the time to explore the question. I predict the set will be low ordered with respect to Ax. Consequently it will be composed of the operators 0..4, inclusive, likely without 4. We&#39;ll see. </p>

<h3 id="toc_37">Three</h3>

<p><code>3</code> is the ax operator, <code>ax</code>, which Nocks a noun apart and evals it. The symbol <code>nck</code> is also reserved for this operator, en homage. Why 3? Well, that&#39;s a digression, while I&#39;ll gloss over. </p>

<p>Consider that there are two ways to index: by zero, and by one. What if you want to contain the damage? Well, you could count (0|1) (1|2) (2|3) 4 5 6, or (0|1) (0|1) (2|3) (3|4) 4, 5, 6. The latter is taxing on our already strained resources. </p>

<p>In certain circles this difficulty is referred to as the &quot;Abyss&quot;. My solution to this difficulty is suggested by ancient texts but the interpretation is to my knowledge completely original. We are all fairly certain the mystery involves both 3 and 11. Let&#39;s leave it at that for now. </p>

<p><code>ax</code> could be 2, but <code>br</code> could not be 3, or we would have [2 1 3 1], and where did that three come from? Also, branch on address 3 is not defined in the reductions. </p>

<p>Note that both the distributive property and <code>ax</code> may safely be made parallel once the cell to calculate both branches is composed. Indeterminate, mutually dependant behavior may be arranged only through abuse of the <code>0</code> branch and the <code>put</code> operator, in the usual fashion. </p>

<h3 id="toc_38">Four</h3>

<p><code>4</code> is the <code>eq</code> operator, which returns 0 if the evaluated cons(subject,object) is equal and 1 if it is not, crashing on an atom. </p>

<p>Why is four <code>eq</code>? Well, it&#39;s our first non-prime operator, if you accept the case that 0 and 1 are neither prime nor non prime. They have a special relationship with multiplication that makes that case plausible; certainly I was taught the primality of one, though the field would appear to have changed its mind. </p>

<p>It could be <code>cel</code>, but as we&#39;ll see, <code>cel</code> should not be 4. <code>eq</code>&#39;s expansion may be thought of as having an &#39;even&#39; test or a &#39;double even&#39; test, that is, it <code>if</code>s on <code>cel</code> (though of course, the reduction does not). If &#39;odd&#39;, test atomic equality, if &#39;even&#39;, apply <code>cel</code>. <br>
Note that all even-numbered operators and idioms have exactly two expansions, that is, they are higher order branching. Even <code>put</code> is capable of branching, depending on implementation.</p>

<h3 id="toc_39">Five</h3>

<p><code>5</code> is the <code>fz</code> operator, one of the raisons d&#39;etre for Ax versus Nock. </p>

<p>Note that in Plan Ax from Conk Space, 5 is <code>cel</code>. </p>

<p>Fully qualified Ax machines are not deterministic, because they aren&#39;t colorblind. In addition to Black and White bits, Ax machines must supply Red bits, which are completely different because they come from an actual, high quality source of entropy. Note that, while weird, this is just as well formed as saying &quot;an actual, high quality source of numeric computations&quot;, in that you can just hop on the Internet and buy one. Ax machines must have both.</p>

<p>This is one reason <code>fz</code> is an operator, rather than a lemma or higher-level function. The Second Law of Thermodynamics is taken as axiomatic for our purposes; within the specification, the method of selecting on the range is deliberately left unspecified.</p>

<p>There are some Deep Implications here, which, as usual, I intend to touch on later. </p>

<p>The demonstration Ax machine uses Pink bits, which are only pseudorandom. This is strictly not compliant, for the purposes of a reference implementation, but I&#39;m in a hurry. Feel free to use Pink bits if you&#39;re just futzing around, but consider making or buying a gig or two of entropy, or picking up an entropy machine. Cheap stuff, entropy, these days. Remember to throw it away as soon as you&#39;re done with it: the first rule of handling entropy is: any operation whatsoever upon it render it <strong>and any copies</strong> no longer entropic. </p>

<p>Because we have a term, not just a preamble and definition, there are an infinite number of possible Ax machines, even Ax α machines. Ours is Ax α 256, aka Ax Byte. The beautiful, Schemish Ax is Ax Bit, of course, but it may easily be emulated with modulo 128, whereas simulating the reverse transition is particularly tedious. </p>

<p>A ternary machine would draw on nine trits of entropy, or whatever. Ax is meant to be used. </p>

<p>Note that randomness is not mentioned in the spec. It is actually perfectly valid for <code>fz</code> to return any number in the range: you may rewind Ax and play it again, or feed it nothing but 128 in all cases, or 0, or anything else you&#39;d like. The treatment of <code>5</code> and <code>br 0</code> distinguishes the actual semantics of an Ax machine, as they introduce indeterminacy into the result. </p>

<p>Why 5? Zod, where else would you put it? There are actual reasons, related to the geometry implied by the new kabbalah. This is beyond our current scope.</p>

<p>Note that we may generate 6 with Ξ [4 5 [2 3]]. Eventually, or immediately, depending on the Ax machine. This is considered beneath demonstration.</p>

<h3 id="toc_40">Six</h3>

<p><code>6</code> is the cell operator, <code>cel</code>. It returns 0 for a cell and 1 for an atom, as you might expect. Symbols are inspected in this case to see what kind of noun they represent. </p>

<p>Why six? Well, there are two important kinds of cells in Ax, [a b] and [a b c], as defined in the preamble. There are two groupings of six, [[1 1] [1 1] [1 1]] and [[1 1 1] [1 1 1]]. If you immediately recognize those are syntax errors, you&#39;re doing great. Happily, Ax is blessed with exactly three relevant data structures, as shown by the first three lines of the reduction: atoms and two cells, which may not be Axed, and 3 cells, which are n cells, and which may be Axed in some cases. </p>

<p>Those are the axioms. I am totally convinced of 0, 1, 2, and 3, which define Ax space within Conk space. I am pretty sold on 4, 5, and 6, and on the benefits of Xa space and the <code>a br 0</code> reduction of 2. </p>

<p>The reasoning behind the order of the idioms is basically Kabbalistic. Surprise surprise, that is the reasoning behind Ax space too. It just <strong>happens</strong> to look like a Page from the Book, as Erdős Pál would say. </p>

<h2 id="toc_41">Idioms</h2>

<p>Nock calls these macros, and defines them as such, though we are advised by the Crash Course that there&#39;s no reason to implement them this way. In Ax we call them idioms, indicating that they may be expanded as macros containing only the axioms. For the reduction, sometimes we do, sometimes we don&#39;t, whatever&#39;s cleanest. Since we have expansion rewrites as well as reductions, anything may be written as a macro, as long as you&#39;re not in a hurry to halt. </p>

<p><code>7</code> is <code>cmp</code>, which composes functions, and which, through happenstance, ended up in the same place as in Nock. We&#39;re in Netzach, if you&#39;re paying attention.</p>

<p><code>8</code> is <code>if</code>, <code>9</code> is <code>cnk</code>, <code>10</code> is <code>put</code> and <code>11</code> is <code>arm</code>. <code>if</code>, <code>cnk</code> and <code>arm</code> work like 6, 8 and 9 from Nock, because they&#39;re identical except for the necessary permutations. <code>put</code> has the same syntax as the other <code>10</code>, and identical semantics: the results are undefined, other than that evaluation must happen if a cell is provided. We don&#39;t plan on using this for hinting, but if we&#39;re running Hoon 191, what other option do we have? </p>

<p><code>put</code> fits nicely in <code>10</code>, because it&#39;s <code>0</code> all over again, having the same meaning for the purposes of the Arc of code under evaluation. The interaction between <code>put</code> and <code>br 0</code> is envisioned as a crucial mechanism in the larger Arcitecture. </p>

<p>I could make a firm case for <code>dec</code> as consonant to <code>inc</code> and <code>arm</code> as consonant to <code>br</code>, giving an opposite mapping. But the lemmas come after the idioms, and <code>dec</code> is clearly a lemma, and that is that. Certainly, the Nock tutorial shows that <code>dec</code> may be (somewhat) compactly specified in terms of the axioms.</p>

<h2 id="toc_42">Lemmas</h2>

<p>Ax comes equipped with the operations you&#39;ll need to have a reasonable Big O on integer algorithms.</p>

<p>You&#39;re welcome.</p>

<h2 id="toc_43">Distinctions between Nock and Ax.</h2>

<p>There are four changes between Nock and Ax: the permutation of the operations, the addition of <code>fz</code>, <code>br 0</code>, and the <code>put</code> operator, to list them in order of seriousness. I have made the case, I believe, that the permutations put the jewel in the heart of the lotus. Perhaps we merely gild the lily. This is a matter of taste, not semantics, but without taste, Nock is pointless. I have devoted a number of paragraphs to <code>fz</code> already. Let&#39;s discuss <code>br 0</code> and <code>put</code>.</p>

<p><code>br 0</code> provides for a very simple and ordinary thing: a number that comes from Outside, that we can only determine if we go and look. A port, say, or a sensor. I don&#39;t know how Hoon deals with this, but I know that Nock does not handle it at all. Ax does: you can hook a very simple piece of Ax up to a sensor and do things with the numbers. I consider this a virtue in a toy computer, and the zero branch was just sitting there being undefined. </p>

<p>I suggest a pleasant detour over to <a href="http://thoughtmesh.net/publish/367.php">Undefined Intimacy With the Machine</a>. It is not only a product of the Cathedral, it is from a field of <strong>critical studies</strong>, called code studies, of course. This guy is right out on the bleeding edge, my friends. </p>

<p>Not all code talks to Outside, but most code comes from Somewhere, and sometimes Somewhere might want to drop a noun or two into the mix. I gather this isn&#39;t what you do with Nock, and again, I bet Hoon provides it. The thing is that Ax machines make no assumption that the whole system is going to be running on one core, in fact they&#39;re decidedly more comfortable if that is <em>not</em> the case. </p>

<p>Could we run Ax machines on a ColorForth array? Zod man, what else are they good for? The Parallela is a less exotic target; if you know any OpenCL, the interaction between <code>br 0</code> and <code>put</code> might be putting you in mind of a &quot;kernel&quot;. Excellent! We&#39;re on the same page. </p>

<p>Why do we need <code>fz</code> though, with all this Undefined Intimacy going around? Well, because of the Rules of the Red Bit, basically. An undefined number is going to be some combination of Black and White when you look at it. A Red Bit is already Black or White, but it got that way in a very special manner, and you&#39;re not allowed to look at it (though you may copy it) or it&#39;s not Red anymore. Not to mention that sealed functions that use <code>fz</code> make perfect sense and should be allowed, and a function either crashes on <code>br 0</code> or does something special with it, but not in general both. </p>

<p><code>fz</code> is axiomatic, and we kind of force you to write your code in weird ways if you absolutely want to be sure it never comes up. It&#39;s a feature! We call it guessing, and have this notion that it makes for cheap machine learning. We hope a group effort can come up with some good uses. </p>

<p>What about this <code>put</code> business? Well, we like the algebraic feature of Ax a lot. We don&#39;t need hints, because it&#39;s quite normal for Ax code to come with both embedded symbols and a table containing expansions for the symbols, as well as jets for the assisted ones. In a mature environment, we scrub this of any taint of variability and anonymize everything, so your <code>foo</code> and my <code>foo</code> will be different even if they happen to be equal (minus yet another layer of abstraction!). As it stands, AxUM is a single computation and all symbols must be distinct and have singular expansions. </p>

<p>We do have code with identical semantics, which seems like an odd choice if we&#39;re forsaking hints. Here&#39;s one good reason: Ax goes to great lengths to be in principle Hoon and Nock compatible. It&#39;s just respectful, and if there&#39;s to be a transition, let&#39;s ease the pain, or delay it insofar as possible.</p>

<p>In fact, use of <code>put</code> will also not affect the semantics of your running code. If you&#39;re in some kind of compatibility mode, you may even find that the use of opcode 10 provides pleasant jet assistance to your calculations. This is not our intended use case: <code>put</code> is the other side of <code>br 0</code>.</p>

<p>Without going into detail that will probably prove wrong, <code>br 0</code> and <code>put</code> define address spaces &quot;above&quot; and &quot;below&quot; the Arc of Ax code that is executing. Nock is Hermetically sealed, which is a virtue; <code>br 0</code> and <code>put</code> provide a formal, very low-level- mechanism for building plumbing between Ax vessels. </p>

<p>Getting this right will be the true test of the Tree of Life on this machine. The Tree is recursive, fractal, heirarchical, and mnemnonic, among other qualities, all of which comes into play.</p>

<p>Importantly, this is defined at a higher level. It will be the canonical way to link Ax machines together, but is not part of the semantics of the machines themselves, on purpose. They&#39;re really quite small. </p>

<p>The main reason for this is that the intricacy of these address spaces will make them in effect kernel-level abstractions. They will end up just as frozen as Ax will, but consequent to that, and with a longer annealing phase. </p>

<h2 id="toc_44">Philosophy</h2>

<p>Well and good, and we all love an elegant mathematical structure. What&#39;s the purpose of some of this? Why an Ax machine, which is inductive, nondeterministic, and redundant, versus a Conk machine, which is crisp, deductive, and minimal?</p>

<p>It&#39;s not an idle question. There are two Conks with the elegance of the Ax machine, which are Ax α with operator 5 replaced with one of the two possible options. Why choose induction and expansion over deduction and reduction? Why even offer the choice? Usually, we choose computers that are known to halt on problems which are known to halt. </p>

<p>Well, Ax isn&#39;t quite that bad. It has a Ko rule, after all. There are two cases to be made, one from elegance and another from utility.</p>

<p>Without expansions, one may not generate the full set of possible operations from a seed. This is a beautiful property in a system, if you&#39;re me, and since the expansion Ξ [0 0 0] -&gt; Ξ [0 2 1] may yield (I am convinced) the other operators, it is a beautiful seed for a beautiful system. This is sufficient justification for the automaton; what is mathematics if not elegance, nor elegance if not a species of beauty? </p>

<p>Utility is perhaps harder to see, but imagine an aging computer in a hostile environment. Though it has megas of cores, many are infected and firewalled, others punctured by radiation or otherwise deranged and useless. The ability to expand a failed reduction may save a calculation, and that&#39;s no minor thing. A failed or malfunctioning jet may be similarly unit tested against its expansion, fractally and repeatedly, and substitutes checked for correctness in the same way. </p>

<p>The expansions are not actually necessary, that is, the reductions serve to define the calculational semantics. They are included, ultimately, as a bridge to the next level of abstraction: grammars which recognize and transform strings of various sorts into Ax. This is perhaps the most profound advantage of using a cellular automaton, and we intend to make good use of it.</p>

<p>So that&#39;s the Ax machine. Maxwell&#39;s equations build each on the others, as Euclid&#39;s Axioms, as the Laws of Motion and Thermodynamics. With the Ax ordering of Nock, the operators produce their own sequence. Quod Erat Demonstrandum.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Executable Representation]]></title>
    <link href="http://mnemnion.github.io/blog/2013/10/06/executable-representation/"/>
    <updated>2013-10-06T12:20:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/10/06/executable-representation</id>
    <content type="html"><![CDATA[<p>I find Urbit interesting for one simple reason: Nock is the most elegant expression of computation I have yet to encounter.</p>

<p>I am no kind of software engineer or computer scientist, at all. I am a professional developer, through a colorful maze of career turns. Curtis Yarvin is trolling when he claims to know no &quot;PL Theory&quot;. I&#39;m not. </p>

<p>As an autodidact on most subjects (I can claim a major in chemistry and a minor in mathematics) my coverage is perforce spotty. McCarthy&#39;s thesis I get well enough; Alonzo Church and Haskell Curry make me nervous. </p>

<p>You know who I do understand? Douglas Hofstadter. Came by that understanding the old fashioned way, by dropping out of highschool for a semester to read GEB:EGB and the Dragon Book, then dropping back in, then dropping acid. The order there is important. Get your diplomas, kids.</p>

<p>I also understand DNA, at least okay. I wrote a vector once, or truthfully, my professor kindly took the time to explain how vectors work in enough detail that writing the actual base pairs out was not entirely transcription. I&#39;ve transfected them into plants, as well as wrapping them in tiny pellets of gold and blasting them into cells with high pressure helium, a technique that goes by the sobriquet &quot;shotgun genetic engineering&quot;. Shotgun indeed. If any of that sounds exciting, may I recommend lathe work? It pays better.</p>

<p>So when I encounter Nock, what I see is Lisp, rewritten as a cellular automaton, capable of serving as a DNA for computational beasties. That somehow encodes the Tree of Life. </p>

<p>Let&#39;s run with that and see where it takes us. </p>

<h2 id="toc_20">A Cellular Lisp Machine</h2>

<p>Many people ask: what on Urth is Nock? Comparisons are made across many abstractions. All of them are interesting, and many are salient. To quote the current #urbit channel topic: &quot;<a href="https://thoughtstreams.io/jtauber/nock/">jtauber</a> oh man, the light just went off that [0 1], [1 b] and [2 b c] are just the I, K and S combinators&quot;. Indeed this may be the case, but I am in no position to judge it.</p>

<p>I luck out here because Nock is exactly on Urth a <a href="http://en.wikipedia.org/wiki/Cellular_automaton">cellular automaton</a> and needn&#39;t be anything else, or make reference to anything else, to do what it does. A different von Neumann machine indeed! An Ulam/von Neumann machine.</p>

<p>I am quite convinced that Nock could not have been designed without reference to more-or-less every important formalism of computation in the literature. <a href="http://en.wikipedia.org/wiki/Hangul">Hangul</a> could not have been designed without intimate knowledge of the <a href="http://en.wikipedia.org/wiki/Hanzi">Hanzi</a>, but knowing the latter is no help at all in using the former. </p>

<p>Cellular automata are easy to understand if you&#39;ve read GEB: Nock takes a string, applies rewrite rules in a definite order, and repeatedly reduces until it returns or loops forever. Looping forever can be trivial or not: detecting loops and deciding what to do about them is interpreter-specific. </p>

<h2 id="toc_21">The DNA of the Urb.</h2>

<p>I happen to believe (on alternating Tuesdays) that DNA, as an abstraction, is something that just shakes out of reality when you get oily water to bubble-bath temperature for long enough. The exact base pairs, the resulting mappings, and the detailed chemistry are more than likely homebrewed for each planet. It would be nice to be wrong, but most likely the very basic proteins of other protein-based life would be allergens at best to our chemistry and vice versa. </p>

<p>If you don&#39;t get me, consider that caffeine makes a perfectly good substitute for A in your DNA, and if you&#39;re a fan of the stuff like I am, your DNA contains a considerable amount of it. On some other planet, caffeine is the standard, and as a result, the alpha helix protein causes us to break out in terrible hives on skin contact. Adenosine-producing plants have a powerful narcotic effect on the native mammals, but their chlorophyll destroys our optic nerves. And so on. </p>

<p>Indeed, we may imagine that early life on Earth had many nucleic acid gangs, locked in struggle, and that our chemistry was most toxic to theirs, and/or theirs least toxic to ours. Perhaps not; such losers have a way of going to ground and remaining in pockets. </p>

<p>The Nock spec could serve as the base pairs of an entire kingdom of number, as DNA is the pillar of the kingdoms of life. That is unabashedly the goal. </p>

<p>Yet number is not matter. There are critical differences. Here&#39;s counting in number: 0, 1, 2, &#8230;, n or aleph depending on your taste. Here&#39;s part of counting in matter: 1, 2, &#8230;., ~<a href="http://en.wikipedia.org/wiki/Uranium">92</a>. Important corrolary: 1.008, 4.002602, 6.94 map statistically to 1, 2, and 3 due to the fact that atoms are complicated. That is only the very beginning of it. </p>

<p>The result is that molecules literally have aroma, flavor, texture, color. Numbers have none of those things without convention, and a lot of it. It is our task as programmers to show good taste in establishing these conventions.</p>

<h2 id="toc_22">Executable Representation</h2>

<p>Curtis Yarvin sells Nock as a VM, which I view as overstatement and undersell. Virtual machines do not merely calculate, they run. The only binary Nock interpreter is hinted and jet assisted: it may calculate Nock, but what it runs is Hoon. </p>

<p>A cynic would say that what it runs is C. I say fie. When we are rewriting strings (these are mathy strings, not computery strings), recognizing a tedious reduction and supplying the result is proper cricket. </p>

<p>What if you want to make something fast (call it Foon) and bypass Hoon? Well, you&#39;re kinda on your own as far as I can gather. The hinting mechanism is used, but is not documented as part of Nock. So write your own Nock interpreter that can run Foon, but it will only calculate Hoon. The HoonNock VM will be able to calculate Foon, but can only run Hoon.</p>

<p>Can this be mitigated? I think it can. One way would be to thoroughly document the hinting mechanism, allowing a compiler writer to target not just Nock, but the existing jets. Extra points for bug compatibility. </p>

<h2 id="toc_23">Not Nock</h2>

<p>Nock is at 5K, though two cosmetic fixes have crept in at that level. I&#39;d call that dodgy, except code temperatures this low have never been measured before. The thermometer cannot by definition be properly calibrated.</p>

<p>Ultimately, I feel Nock may be made to serve. Still, my brain runs at a few notches above room temperature, and it&#39;s interesting to think about how Nock could be changed.</p>

<p>Here&#39;s what I wouldn&#39;t touch a hair on:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>A noun is an atom or a cell.  An atom is any natural number.  
</span><span class='line'>A cell is any ordered pair of nouns.</span></code></pre></td></tr></table></div></figure>

<p>A righteous man might say &quot;Amen&quot; here. I&#39;ll say right on. </p>

<p>I would like to draw the Reader&#39;s attention to the second sentence. It contains the fateful words &quot;natural number&quot;. The camel pokes her nose into the tent. </p>

<p>So normally when we make formal systems that rewrite strings, we use symbols. See Lisp and GEB for the two cases that matter most here, and check out Game of Life again for extra credit: it&#39;s not just Turing complete, but demonstrably self-hosting. </p>

<p>Oh hey, if you want to really impress me, design a Game of Life emulator in Game of Life and then demonstrate Godel incompleteness with it. </p>

<p>Natural numbers, though. A fine choice that shows excellent taste. Not just any set of symbols! <strong>The</strong> set of symbols. Except it&#39;s not a <a href="http://en.wikipedia.org/wiki/Abstract_algebra">set</a>, is it. Indeed it is not: behold the face of the camel. She smells something she likes. It&#39;s warm in here. </p>

<p>We are treated to a punky, fresh set of operators / rewrite rules that let us compute to our computer&#39;s content. Only basic arithmetic escapes cgy&#39;s benign and giving nature here. We are given increment as a warmup, and it would seem entire Dukedoms were awarded on the basis of decrement. I wonder if I could still score a cruiser for multiply. Do I get more points for O(n<sup>4),</sup> or less?</p>

<p>My goodness this beast has a lot of neck. Here, let me move the hookah. In providing only increment I see the logic, but not the wisdom. Worse, I don&#39;t see the sense. It was magnaminous to provide the macros, though it may have been done merely to answer the calls of &quot;you cannot possibly use that faster than Brainfuck&quot; that would have followed such a skeletal machine. </p>

<p>Thing is, when someone says &#39;natural numbers&#39;, they have promised a perfectly well-defined subset of operations, which Nock distains to provide. Hoon can do math; Nock just looks at you and says &quot;i++;&quot; a lot. </p>

<p>Decrement is explained with much fanfare. Indeed most of my actual applicative understanding of Nock comes from that explanation. It&#39;s a simple case, because there&#39;s only one bad value to decrement, namely zero. It&#39;s also fairly obvious what to do: crash. </p>

<p>Add, multiply, integral division and modulus are entirely specified under the two words &quot;natural number&quot; and it is camelnine not to include them. Look, let me show this creature out: she&#39;ll start spitting or worse, and I like this rug. A div 0? Crash or fisticuffs, sir.</p>

<p>Consider line 7. It plainly says &quot;By add, we mean a restricted subset of addition, namely, addition by one&quot;. A little coda saying &quot;oh yeah actually adding stuff in the general case of two arguments? 14&quot; would not instantly bloat our automaton into JVM proportions. </p>

<p>Subtract, though. I could see that going two ways for bad input. One would be to crash; it&#39;s the natural thing to do. Another option would be to return a cell with 1 at the head and the result of subtracting b from a rather than a from b at the foot. We might call it a negative number, or a useful error message. It&#39;s plausible is it not? Perhaps my Nock machine could jet assist this case and yours could absolutely plod. Clearly code allergy could be the only result. </p>

<p>We do not want code allergy at the level of arithmetic. The only option given the Nock spec is to blindly follow the Hoon spec. I detect an abstraction leak.</p>

<p>Where on Urth could we put these extra operators? </p>

<p>The back of the T shirt, of course. There should be plenty of room under the silkscreened all-seeing Eye.</p>

<h2 id="toc_24">Call it Ax</h2>

<p>Nock is unlikely to change. It&#39;s clear that Curtis Yarvin has thought this through, carefully, and simply come to a different conclusion from my own. I don&#39;t expect he will say &quot;By Zod, your camel is completely persuasive&quot; and go rewrite everything. </p>

<p>If I had my own toy Kabbalistic computer, which I do not, it would be called Ax. Ax would be a cellular automaton that has the same preamble as Nock, and a similar structure. There are some good reasons for it to be operator-compatible with Nock, but not many, since it would hit the humble minus of Hoon and rip through each loop unless propped up with some kind of unholy JITing. </p>

<p>So let&#39;s cut the umbilicus and call this automaton Ax. It has two lines of specification. The rest of this post will not add any. Sorry, yo.</p>

<p>Ax would have a longer spec than Nock. That&#39;s okay; Euclid is also longer than Nock, and it&#39;s pretty good. Making it shorter wouldn&#39;t make it better, though I&#39;m sure there are some steps which we consider repetitive today. That&#39;s because it was written for doing geometry, not just for proving it. </p>

<p>Ax would also lack an operator which Nock has, namely 10. Clearly, it may be reconstructed, as it&#39;s but a macro. It won&#39;t be a hint, though, because hints make me nervous. Jets don&#39;t, I emphatically agree with jet propulsion (though not of * for pity&#39;s sake), but hints. I believe I have a scheme for organizing Ax code so that hints aren&#39;t needed or even useful. This post is going to be a two parter.</p>

<p>I do have a question about 10 that is illustrative. It is said to expand thus: <code>*[a 10 [b c] d]   *[a 8 c 7 [0 3] d]</code>. The question is: if one were to open up some Hoon-compiled nock, and replace a 10 with the expansion, would the jet fire?</p>

<p>This seems like the sort of question which cannot be settled by reference to the Nock spec. While the Hoon source resolves it in a sense, that is not fully satisfactory either. </p>

<p>I&#39;m mulling over making 10 a <code>put</code> operator, that discards an atom or a calculation, with the semantics &quot;something else might do something with this value in an implementation-dependent way&quot;. Such a tool is drenched in Midichlorians and could be used for great evil or great evil masquerading as good intentions. I&#39;m not opposed necessarily, but I am skeptical of my own urges here.</p>

<p>That would be similar to allowing a calculation to slot on 0 and for any old thing to be in 0, even fairy dust. Gives me shivers just thinking about it.</p>

<h2 id="toc_25">A Blizzard of Cores</h2>

<p>Having a magic 0 address and the ability to mysteriously <code>put</code> data somewhere else isn&#39;t just provocative fashion sense. It&#39;s a loose mapping to the structure of OpenCL, with which we might Use the Cores. I want to Use the Cores, but if your code has pointers, I can&#39;t do that. </p>

<p>We abandon any pretense of having a deterministic machine with such a move. <code>put</code> may be made well defined at a higher level, but a magic address is magic, and we are undone. That&#39;s okay. I was going to do that anyway. </p>

<h2 id="toc_26">Coloured Bits</h2>

<p>Ax would differ from Nock in one key dimension, which I doubt can be resolved. Nock is <a href="http://ansuz.sooke.bc.ca/entry/23">Colour blind</a>, while Ax will be able to detect the Colour of your bits. Clearly to be automatically compliant with law across all juridictions and boundaries, a legal calculation must be able to detect, say, that the input belongs to Columbia Studios, the output belongs to a home theatre, and the combination is not allowed. </p>

<p>Ahem. Colour at such a level is a Layer Four / Urbit concern which Nock nor Ax could possibly handle. There&#39;s a gem buried in that link: namely, that randomly generated numbers have a Colour which we must respect if we want to work with them. Which, y&#39;know, we might.</p>

<p>One of the powerful ideas of Urbit seems is that, instead of Facebook and Google, there can be <em>my</em> facebook and <em>my</em> search engine. What Facebook and Google are supposed to do, respectively, is guess which content from my friends I&#39;d like to see and guess what I&#39;m looking for based on a search string. Modulo ads, they succeed reasonably well. Modulo ads, there&#39;s less and less left.</p>

<p>It would be nice if taking a guess was easy, cheap, and moronically simple. Simple like XORing an atom against an always-available pool of entropy and memoizing the result with the atom, thus preserving both the entropy and the computation in the same amount of space it would take to preserve the computation&#39;s inputs. That can of course be shimmied in at a higher level on a deterministic machine. Such a shim would be expensive. I want guesswork to be really, really cheap. </p>

<p>So Ax has three Colours of bit: black, white, and red. Red bits are resolved when needed from a presumed infinite pool of high-quality entropy. It has an operator, <code>fuzz</code>, which opens an enormous can of worms. What happens when you XOR entropy across 27? </p>

<p>Mu, is what. You can&#39;t XOR something that isn&#39;t binary. Nock deliberately and throughly rejects bits in favor of natural numbers, and drives the point home by describing them in decimal. Ax doesn&#39;t get this luxury. Longer spec. The rule is probably &quot;take as many low bytes from the atom as specified by the byte width of the entropy call&quot; or something similarly convoluted. </p>

<p><code>fuzz</code> should come before the macros, as it cannot be defined as one. There is no point in operator-level compatibility with Nock. It would be far easier to retarget Hoon at Ax, or more likely, virtualize the NockHoon VM on top of Ax directly. Like I said, two part post. </p>

<p>Any function which has <code>fuzz</code> in it or which contains a <code>slot</code> on the 0 address is not deterministic. Otherwise, it is. The intention is to build some higher level conventions on top of that which allow for flexible communication with running Ax code (infinite loops are not all errors) and for building whatever sort of reasoning engine one might want. Assuming a limitless pool of entropy is a <a href="http://en.wikipedia.org/wiki/Comparison_of_hardware_random_number_generators">safe bet</a> for future systems, and cheap to provide for current ones. </p>

<p>We can let you cheat and use pseudorandom Pink bits, if you&#39;re willing to assume the consequences. Which for ordinary guesswork are presumably not dire. </p>

<h2 id="toc_27">Other Esoterica</h2>

<p>Here&#39;s a question: if you took Nock, and permuted the operators, so that 4 is say 7 and so on, would it work?</p>

<p>Provisionally, my answer is &quot;yes&quot;. That is, one could target that virtual machine and perform general calculations and nothing would be Wrong. I&#39;ve talked this one over with <a href="https://github.com/jtauber/pynock/blob/master/nock.md">jtauber</a>, who really gets this Nock business.</p>

<p>Let&#39;s call the permuted Nock machine Conk. </p>

<p>Second question: could you statically recompile Nock code into Conk code by permuting the operators in the same way and have it run on the new machine?</p>

<p>Clearly not. Nock can calculate a number and then use it as an operator, and this calculation would fail on Conk machine. Two increments on 0 can return 2, and then 2 can <code>*</code> on something; that doesn&#39;t work if <code>*</code> is 6.</p>

<p>Could one use some kind of reader table to change the meanings of operators when encountered, so that the permutation machine could be used, by swapping one layer for another, as a Nock machine? I believe so, I can&#39;t come up with a reason it wouldn&#39;t work. One needs a dispatch table, why not several? The hard part of running Nock on Conk is not dispatching the operators, it is sensibly firing jets when necessary. </p>

<h2 id="toc_28">On Beyond Hinting</h2>

<p>This post will have a part two at some point. That&#39;s a discussion of a scheme for compressing Ax/Nock code in a way that should let us dispense with hinting altogether. It&#39;s half-baked and frozen, and it may take some time before I can pull it out and brown it. </p>

<p>A better use of time is going to be finishing off a usable alpha of <a href="http://mnemnion.github.io/blog/2013/08/03/a-tangled-web-we-weave/">Marmalade</a>. Marmalade can be used directly to knock down the conceptual burden of writing and understanding the rest of the software. I consider an Ax/Nock machine running over OpenCL to be step three. </p>

<p>Step two could be a fun blog post, but there&#39;s a rule of thumb: if you emit too much vapor, it&#39;s a safe bet some is coming out of your ass. Playing with Urbit is more rewarding. Or will be when ~doznec is back online&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Urbit Has Landed]]></title>
    <link href="http://mnemnion.github.io/blog/2013/10/05/the-urbit-has-landed/"/>
    <updated>2013-10-05T10:41:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/10/05/the-urbit-has-landed</id>
    <content type="html"><![CDATA[<p>At long last, <a href="http://urbit.org">Urbit</a> has landed. The Internet is bewildered, flummoxed, and intrigued. </p>

<p>I encountered Urbit (and <a href="http://unqualified-reservations.blogspot.com">Moldbug</a>) when the original <a href="http://moronlab.blogspot.com/">Moron Lab</a> posts dropped on HN. Unless it was through <a href="http://loper-os.org">LoperOS</a>, who incidentally might want to get his tail moving. Either way, I wasn&#39;t programming computers then, and I am now, and that&#39;s not a coincidence. </p>

<p>See this one time, I had a vision. I&#39;m sure my <a href="http://en.wikipedia.org/wiki/Dimethyltryptamine">dimethyltryptamine</a> levels were elevated, since you can&#39;t have visions (or dream) without that being the case. It would be impossible to explain, and has proven very difficult to draw. But what it told me is that the Kabbalah, specifically the <a href="http://en.wikipedia.org/wiki/Sefer_Yetzirah">Tree of Life</a>, holds the key to a Kabbalistic Computer. </p>

<p>So reading the Nock spec was a revelation, because you can map it to the Tree of Life. I haven&#39;t been able to suss out whether this was cgy&#39;s intention, he&#39;s cagey as a mockingbird. He&#39;s also a fellow Yid whose passion for the classics exceeds mine by a full order: it&#39;s improbable in the extreme that this is coincidence. </p>

<p>This whole post will be steeped in Kabbalah. You think Hoon semantics are weird, watch out. At least I&#39;m not making this stuff up. </p>

<h2 id="toc_10">A Grove of Pomegranates</h2>

<p>Kabbalah, and Hermeticism in general, is not religion. Nor is it science. To call it philosophy is merely to acknowledge that it is too old and crufty to be more specifically typed. </p>

<p>It has a non-trivial relationship to actual mathematics. By far the best modern work of Hermetics is Christopher Alexander&#39;s <a href="http://en.wikipedia.org/wiki/The_Nature_of_Order">&quot;Nature of Order&quot;</a>, though I haven&#39;t a clue if Mr. Alexander would consider it to be such a thing. </p>

<p>I mean non-trivial exactly: Hermetics cannot be reduced to mathematics, nor vice versa. Where there is no mapping, one or several await discovery. </p>

<p>Hermetics means &quot;that which is proper to <a href="http://en.wikipedia.org/wiki/Hermes">Hermes</a>&quot;, which should not be misunderstood as a religious sentiment. We might call engineering Vulcanics by the same trick (I consider interchangeable use of Latin and Greek to be strength, not sin); the Rod of Asklepios means medicine and implies no belief whatsoever in Olympian deity. </p>

<p>You will find no Wikipedia article on Hermetics, though <a href="http://en.wikipedia.org/wiki/Hermeticism">Hermeticism</a> is covered. We pick our isms carefully over at Unit of Analogy, and aren&#39;t signing up for this one. There is considerable sympathy. </p>

<p>The Pardesh ha&#39;Rimonim, the grove of pomegranates, is a common image in Kabbalah. Which means &quot;the received&quot;. One will find a QBLH desk at every hotel in Israel. </p>

<p>The Tree of Life (in orthodoxy) is an arrangement of the numbers 1 through 10. Each of these Sephirah (the name for number treated in this fashion) is fractal, containing an entire Tree of Life within it. Furthermore, 1 is 10, and there are four levels which repeat between the Ultimate and the Real. They are called Atziluth, Briah, Yetzirah and Assiah. The manifest is not even Assiah, it is merely our picture of Assiah.</p>

<p>Gibberish? No, <a href="http://en.wikipedia.org/wiki/Yiddish_words_used_in_English">Jargon</a>. You will find the identical scheme in Plato and in Tantric thought. That&#39;s likely to be cribbing, not parallel invention. From whom? Good question.</p>

<p>I will be using jargon, and worse, translating it on the fly into a mapping I completely made up. Can&#39;t be helped.</p>

<p>As a statement about ontology, let&#39;s set it aside for today. According to the <a href="http://en.wikipedia.org/wiki/Terence_McKenna">elves</a>, it&#39;s a diagram of the network layers. How do we go from the conceptual (we have an urge to calculate) to the realized (here is a machine which does so)? </p>

<p>Any which way we want to, of course! What Would <a href="http://en.wikipedia.org/wiki/Isaac_Luria">Ari</a> Do? </p>

<h3 id="toc_11">Lolwhut</h3>

<p>Look, you already have a spaceship written in the language of horse-headed beasts which eat Yahoos. </p>

<p>I&#39;m taking it for granted that you can handle a little colorful metaphor. </p>

<h2 id="toc_12">Layer Zero</h2>

<p>The zero layer is of course physics. Let&#39;s try to stick with things that work on that substrate.</p>

<h2 id="toc_13">Layer One</h2>

<p>This is Atziluth. It is our calculation represented literally, as a calculation. In a word, Nock. </p>

<p>Nock is a work of praeternatural brilliance. I will save all critique for a later post. Let&#39;s pretend it&#39;s perfect, as indeed it is. </p>

<p>Let&#39;s note, though, that to get Layer One running on Layer Zero (our chip) requires a bit of cheating from Layer Three. Can this be avoided? Perhaps.</p>

<h2 id="toc_14">Layer Two</h2>

<p>Layer Two is missing from the Urbit stack, or rather, it is conflated with Layer Three. I see how that happened. It&#39;s tempting. It may even be fixable from within the existing structure. </p>

<p>Let me break down how, in ol&#39; QBLH, something might travel down this ladder. There&#39;s some primal Thirst that is the same thirst no matter what experiences it, anywhere in Universe. So goes the premise. That&#39;s Atziluth. Briah is where an I forms an urge that is a personal thirst. Yetzirah is where this coalesces into an action, in Assiah the action is actually taken, and then the individual experiences a theatrical performance of the act of drinking water, assembled by his or her neural cortex. </p>

<p>Is that last point at all unsettling to you, dear Reader? I should hope not. It is on the firmest of ground, however shaky the rest may be.</p>

<p>That&#39;s the metaphor for our network stack. The Briatic layer is specification of form. In perfection it would be purely declarative, and the form it should take is ancient and not open to debate: it is, should be, ultimately must be, a grammar.</p>

<p>Not a powerful set of gonads. A grammar. <a href="https://github.com/epsil/gll">GLL</a> is totally a thing and for the first time we can make performant grammars that are as expressive as <a href="http://en.wikipedia.org/wiki/P%C4%81%E1%B9%87ini">Pāṇini</a>. </p>

<p>Here&#39;s some Hoon: </p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>         %r
</span><span class='line'>        =+  yug=(yell q.p.lot)
</span><span class='line'>        =&gt;  ^+(. .(rex ?~(f.yug rex ['.' (s-co f.yug)])))
</span><span class='line'>        :-  '~'
</span><span class='line'>        ?:  &(=(0 d.yug) =(0 m.yug) =(0 h.yug) =(0 s.yug))
</span><span class='line'>          ['.' 's' '0' rex]
</span><span class='line'>        =&gt;  ^+(. ?:(=(0 s.yug) . .(rex ['.' 's' (a-co s.yug)])))
</span><span class='line'>        =&gt;  ^+(. ?:(=(0 m.yug) . .(rex ['.' 'm' (a-co m.yug)])))
</span><span class='line'>        =&gt;  ^+(. ?:(=(0 h.yug) . .(rex ['.' 'h' (a-co h.yug)])))
</span><span class='line'>        =&gt;  ^+(. ?:(=(0 d.yug) . .(rex ['.' 'd' (a-co d.yug)])))
</span><span class='line'>        +.rex
</span><span class='line'>      ==</span></code></pre></td></tr></table></div></figure>

<p>This, I am told, specifies the syntax of a floating point number. Or some of it does.</p>

<p>This is from the JSON spec:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>number
</span><span class='line'>    int
</span><span class='line'>    int frac
</span><span class='line'>    int exp
</span><span class='line'>    int frac exp 
</span><span class='line'>int
</span><span class='line'>    digit
</span><span class='line'>    digit1-9 digits
</span><span class='line'>    - digit
</span><span class='line'>    - digit1-9 digits 
</span><span class='line'>frac
</span><span class='line'>    . digits
</span><span class='line'>exp
</span><span class='line'>    e digits
</span><span class='line'>digits
</span><span class='line'>    digit
</span><span class='line'>    digit digits
</span><span class='line'>e
</span><span class='line'>    e
</span><span class='line'>    e+
</span><span class='line'>    e-
</span><span class='line'>    E
</span><span class='line'>    E+
</span><span class='line'>    E-</span></code></pre></td></tr></table></div></figure>    

<p>The former is executable, the latter is admirably clear. These advantages can be combined profitably. </p>

<p>This is not even a critique of Hoon the language, because we haven&#39;t gotten to Level Three at all. This is an assertion that Hoon is poorly suited to specify any data format which may be expected to be used by anything but the Urbiverse. I consider that a deficit.</p>

<p>Thing is, I&#39;m pretty sure those gonads can be whipped into a nice powerful GLL for parsing binary data. Hoon is not leading the pack as a choice for the first implementation; that&#39;s a simple matter of documentation, namely the lack of it. </p>

<h2 id="toc_15">Level Three</h2>

<p>Level Three is the Executive layer, wherein we get to specify what we want our machine to do. Generally that&#39;s a programming language of some sort. </p>

<p>Here the difference in approach becomes clear. From cgy&#39;s perspective, Urbit&#39;s Level Three is written in Hoon. From my perspective, Urbit&#39;s L3 is written in Hoon, C, Nock and Markdown. </p>

<p>That is because humans execute, not machines. Machines don&#39;t rush to the wall and plug in when they&#39;re low on juice, at least not yet. For a calculation to happen, a person (I can only introduce you to human persons, but let&#39;s not be prejudiced) must know that they want to calculate, and must know how to do it.</p>

<p>I defy you to do anything at all with only Hoon. Without any reference to Urbit&#39;s Markdown files, or rather, their conveniently compiled HTML derivatives. Hell, I can&#39;t do anything with Hoon yet, even with existing documentation. That can only improve and is no criticism at all at this stage of the project. </p>

<h3 id="toc_16">Houyhnhnm</h3>

<p>I could like Hoon. I want to like Hoon. I cannot seriously credit the idea of One Language to Rule Them All. If I could, it would not look even vaguely like either Perl or APL. No offense to the Admiral.</p>

<p>If I could credit the idea of the UrTongue, it would clearly need to be a format capable of usefully embedding any existing or contemplated programming languages, <a href="https://help.github.com/articles/github-flavored-markdown">cleanly and usefully</a>. </p>

<p>I would strongly recommend to anyone considering designing a new language at the present time: The sequence <code>\n```</code> is utterly reserved and I will come down on you like a ton of tiny Internet bricks if you tamper with that convention. I suspect the present dominance of github is sufficient motive to keep it real. </p>

<p>This leads to a couple important questions: Will Hoon, presuming decent tutorials and documentation, prove a pleasant systems language? More specifically and urgently, will it be pleasurable to write parsers and compilers in? </p>

<p>I am sold on one aspect of Hoon: as the Urbit core and bootstrap sequence. Why? Because it&#39;s there, brah. </p>

<p>I think cgy gets this. The deal with Unix is clear: you can have any language you want, as long as it&#39;s C. I hope the same bargain between Urbit and Hoon will prove to be the upgrade we all want. </p>

<p>Again, having a nice tight Layer Two spec would make this all the more likely. </p>

<h2 id="toc_17">Level Four</h2>

<p>You can&#39;t execute without an environment, which is fundamentally about data in aggregate. That&#39;s Urbit, which is fantastic. The surface area is a set of rules on strings that produces a &quot;directory&quot; and you should just <a href="http://www.urbit.org/2013/08/22/Chapter-1-arvo.html">read the docs</a> because they&#39;re pretty good. It&#39;s URL safe, which is nifty. </p>

<p>I am cheerfully unclear on how any of that operates under the hood. I have notions of how it should work, but no way to contrast that to how it does work. It appears to work, in that pre-alpha-software way. I&#39;d wager the problems we&#39;re seeing right now aren&#39;t design-level. </p>

<p>This is the Assiah layer, which is the world you actually wander around in when you go get your drink of water. If anyone is still keeping track. </p>

<h3 id="toc_18">Okay. That was arcane. Your point?</h3>

<p>Here&#39;s a helpful table:</p>

<table border="1" bordercolor="#00000" style="background-color:" width="100%" cellpadding="3" cellspacing="3">
    <tr>
        <td><em>Kabbalah</em></td>
        <td><em>Urbit</em></td>
        <td><em>Arc</em></td>
    
    </tr>
    <tr>
        <td>Atziluth</td>
        <td>Nock</td>
        <td>AX</td>
    </tr>
    <tr>
        <td>Briah</td>
        <td>Gonads</td>
        <td>GGF</td>
    </tr>
    <tr>
        <td>Yezirah</td>
        <td>Hoon</td>
        <td>Marmalade</td>
    </tr>
    <tr>
        <td>Assiah</td>
        <td>Urbit</td>
        <td>ArcOS/Arcive</td>
    </tr>
    <tr>
        <td> 　 </td>
        <td>  　</td>
        <td>  　</td>
    </tr>
</table>
  

<h3 id="toc_19">Huh.</h3>

<p>I&#39;m sure that made everything much clearer!</p>

<p>The names on the right are referents without value in the present. Unless you count a bunch of Markdown and a partially specified grammar description language. From my modest perspective, that&#39;s code, since I can compile it; it does nothing but inform, and even in that capacity is not ready for public consumption. </p>

<p>The Arc doesn&#39;t exist and needn&#39;t be written if Urbit will serve. By the very nature of the name, it&#39;s a huge, ballsy target. It&#39;s utterly vaporous, though I hope to release the first tool in the chain before the end of the year. That would be <a href="http://mnemnion.github.io/blog/2013/08/03/a-tangled-web-we-weave/">Marmalade</a>, the literate Markdown dialect. The first metacircular compiler of Marmalade is in Clojure, but the lovely thing about <a href="https://help.github.com/articles/github-flavored-markdown">Git Flavored Markdown</a> is that one may embed any number of languages in it. Indeed that is rather the point. </p>

<p>In following posts I&#39;ll go over the cake, layer by layer, with less attention to Urbit and more to a hand-rolled, idiosyncratic take on the same domain. I&#39;ll remind the Reader that there&#39;s no substitute for working code, which cgy haz and I haz not. </p>

<p>In the meantime, Urbit is here, utterly fascinating, and on the verge of working. Come check out #urbit on freenode, and join in the madness. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Decimation]]></title>
    <link href="http://mnemnion.github.io/blog/2013/10/01/on-decimation/"/>
    <updated>2013-10-01T10:20:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/10/01/on-decimation</id>
    <content type="html"><![CDATA[<p>I commonly see the word &quot;decimate&quot; used quantitatively, to mean &quot;to reduce by 90%&quot;.</p>

<p>So commonly, in fact, that I consider it correct. </p>

<p>Yes, yes. In Latin, it means &quot;to reduce by 10%&quot;, which doesn&#39;t sound very scary unless you&#39;re a Centurion awaiting the drawing of lots. </p>

<p>That&#39;s Latin. In English, having a word for &quot;knocked down by an order of magnitude&quot; is useful. We have, fortunately, not retained decimation as a form of punishment. &quot;to reduce by 90%&quot; is also closer in feeling to the qualitative meaning, &quot;to desolate emotionally&quot;. </p>

<p>I was prompted to write this when someone described traffic as &quot;literally decimated&quot; when occupancy of a highway reaches a certain number. It occurred to me that he or she was right to do so. Your useage may vary. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Parenthetical Observation]]></title>
    <link href="http://mnemnion.github.io/blog/2013/09/11/a-parenthetical-observation/"/>
    <updated>2013-09-11T10:38:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/09/11/a-parenthetical-observation</id>
    <content type="html"><![CDATA[<p>Everyone, when they encounter Lisp for the first time, has trouble with the parentheses. It&#39;s a rite of passage. </p>

<p>Everyone who goes on to learn Lisp develops a <em>very</em> different attitude. I&#39;d like to share an observation that helps understand why.</p>

<p>I write a fair amount of Lisp, in a few dialects. I could get that work done without a &quot;)&quot; key on my keyboard. </p>

<p>Lisp means never having to close your forms. The delimiters on the left are for you to read, the ones on the right are just a period. </p>

<p>I find it interesting that anathema accumulates around code barriers, rather than internal syntax. Semicolons, significant whitespace, brace placement, and parentheses have all been the subject of holy war, and one may easily find developers who simply refuse to work with certain separation styles unless pressed. At the moment I can&#39;t account for this observation, but I&#39;d like to note that I&#39;ve never seen a holy war over, say, <code>:=</code> vs <code>=</code> vs <code>&lt;-</code>. Perhaps I&#39;m not on the right mailing lists. </p>

<p>On the other hand, capitalization and underscore vs. slash vs. nothing are certainly capable of eating up arbitrary amounts of bad blood. Never underestimate the geek&#39;s capacity to bikeshed. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why I Am Lisp 2]]></title>
    <link href="http://mnemnion.github.io/blog/2013/09/04/why-i-am-lisp-2/"/>
    <updated>2013-09-04T09:44:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/09/04/why-i-am-lisp-2</id>
    <content type="html"><![CDATA[<p>First things first: Lisp 1 and Lisp 2 are the worst sort of jargon, because they mean exactly nothing without explanation. Renaming them is even worse.</p>

<p>I&#39;ve done this kind of bad abstracting before, in public even. Be careful when naming things. Nouns are sticky.</p>

<p>For those who don&#39;t speak Boston Yiddish, Lisp 1 means that symbols and functions share a namespace. In Lisp 2, they do not. Simple as that.</p>

<p>Of the Big Four, Clojure and Scheme are Lisp 1. Common Lisp and Emacs Lisp are Lisp 2. Yes, elisp is at least as important as the other three.</p>

<p>Having worked at this point with three of the four, Scheme excepted, I prefer Lisp 2. One simple reason: a function is linguistically a verb. If we don&#39;t make a separate namespace for &#39;variable&#39; uses of symbols, we can&#39;t have separate nouns and verbs. This is somewhat uncomfortable in practice.</p>

<p>Ultimately, I feel that this problem arises from a peculiarity of English: The standard way to verb a noun, in the third person (which is what is used for the imperative), involves no change whatsoever to the noun. If we have a list, we list it. There are hundreds of valid verbs which are letter-identical to a corresponding noun, and it is increasingly easy to create more. Thanks Joss Whedon! No, seriously, thanks, it fits English like a glove.</p>

<p>Contrast with a language like Spanish, where there are quite few verbs which cannot be letter distinguished from a noun. It&#39;s a shame computer language design is so heavily influenced by English. A Spanish programming language would be a pleasure to work with, and I can only begin to imagine the sophistication possible in an Arabic or Hebrew based programming language that makes clever use of the Semitic roots and mutations.</p>

<p>Meanwhile, back on this planet, we benefit from separate noun and verb slots in a symbol. <code>funcall</code> is a small price to pay.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[In Which We Build Zeus]]></title>
    <link href="http://mnemnion.github.io/blog/2013/08/04/in-which-we-build-zeus/"/>
    <updated>2013-08-04T18:59:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/08/04/in-which-we-build-zeus</id>
    <content type="html"><![CDATA[<p>Athena is our weaver. This is her source file. </p>

<p>As we are writing a weaver, it happens that we do not have one. This file must perforce be hand woven until Athena may take over. Asking a Goddess to take over any process should not, and shall not, be done casually. </p>

<p>Athena is written in <a href="https://help.github.com/articles/github-flavored-markdown">Git Flavored Markdown</a>, a format designed around code sharing. The executable parts are written in <a href="http://clojure.org">Clojure</a>, using the <a href="https://github.com/Engelberg/instaparse">Instaparse</a> parsing library. </p>

<h1 id="toc_8">Hymn</h1>

<p>Hail, fleet footed Hermes, beloved of Athena!</p>

<p>Hail, Pallas Athene! Hear the ancient words:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>I begin to sing of Pallas Athena, the glorious Goddess, bright-eyed,  
</span><span class='line'>inventive, unbending of heart,  
</span><span class='line'>pure virgin, saviour of cities,  
</span><span class='line'>courageous, Tritogeneia. Wise Zeus himself bare her  
</span><span class='line'>from his awful head, arrayed in warlike arms  
</span><span class='line'>of flashing gold, and awe seized all the gods as they gazed.  
</span><span class='line'>But Athena sprang quickly from the immortal head 
</span><span class='line'>and stood before Zeus who holds the aegis,  
</span><span class='line'>shaking a sharp spear: great Olympus began to reel horribly 
</span><span class='line'>at the might of the bright-eyed Goddess, 
</span><span class='line'>and earth round about cried fearfully,  
</span><span class='line'>and the sea was moved and tossed with dark waves,  
</span><span class='line'>while foam burst forth suddenly:  
</span><span class='line'>the bright Son of Hyperion stopped his swift-footed horses a long while, 
</span><span class='line'>      until the maiden Pallas Athena had stripped the heavenly armour 
</span><span class='line'>      from her immortal shoulders.  
</span><span class='line'>And wise Zeus was glad. </span></code></pre></td></tr></table></div></figure>

<p>And so hail to you, daughter of Zeus who holds the aegis!<br><br>
Now I will remember you and another song as well.  </p>

<h2 id="toc_9">Bootstrap</h2>

<p>To bootstrap Athena, we write a restricted program. It does not weave, so much as extract and concatenate code.</p>

<p>We then write more Markdown that specifies a macro format, also in this restricted format. We use our first weaver to weave both generations of the project into Athena, which will then be more broadly useful. </p>

<p>This first weaver will be known as zeus. zeus is, of course, that from which Athena will spring full-born. </p>

<p>Clojure projects are typically generated with <a href="https://github.com/technomancy/leiningen">Leiningen</a>, and Athena is no exception. Leiningen projects are specified in a root directory file called <code>project.clj</code>. </p>

<p>This is project.clj:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">defproject </span><span class="nv">athena</span> <span class="s">&quot;0.1.0-SNAPSHOT&quot;</span>
</span><span class='line'>  <span class="ss">:description</span> <span class="s">&quot;Athena: a Weaver of Code&quot;</span>
</span><span class='line'>  <span class="ss">:url</span> <span class="s">&quot;http://github.com/mnemnion/marmion/athena&quot;</span>
</span><span class='line'>  <span class="ss">:license</span> <span class="p">{</span><span class="ss">:name</span> <span class="s">&quot;BSD 2-Clause License&quot;</span>
</span><span class='line'>            <span class="ss">:url</span> <span class="s">&quot;http://http://opensource.org/licenses/BSD-2-Clause&quot;</span><span class="p">}</span>
</span><span class='line'>  <span class="ss">:dependencies</span> <span class="p">[[</span><span class="nv">org.clojure/clojure</span> <span class="s">&quot;1.4.0&quot;</span><span class="p">]])</span>
</span></code></pre></td></tr></table></div></figure>

<p>In order to weave code, in general, we need a macro format. This may be made as flexible as necessary. The minimal requirement is the ability to specify a macro name, and expand those macros into files. </p>

<p>This is weaving in its essence.</p>

<p>The above code contains no macro, yet. Writing macros in a Lisp is of course pleasurable and powerful, and Clojure is no exception, having definable <a href="http://clojure.org/reader">reader macros</a>. Soon, we will define one.</p>

<p>First, however, we need a parser that can extract our code. For that, we need to add <a href="https://github.com/Engelberg/instaparse">Instaparse</a>.</p>

<p>Time to fire up <a href="https://github.com/bodil/catnip">Catnip</a> real quick. Be back soon!</p>

<p>What we&#39;re doing next is adding Instaparse to our project. To do this, we have to tell Leiningen to grab Instaparse, which we must do from the config file. This is normally found at <code>~/.lein/profiles.clj</code>; if it&#39;s not, I hope you know what you&#39;re doing. We add the string <code>[instaparse &quot;1.2.2&quot;]</code> to the <code>:plugins</code> vector.</p>

<p>That done, start or restart your project in Catnip, <a href="http://emacs.org">Emacs</a>, or however you like to do it. You must launch with <code>lein</code>, which is totally conventional.</p>

<p>This being a bootstrap, we will need to resort to some custom syntax in our Markdown. As we extract the source, we will encounter various <code>@magic words@</code>, which the parser will do various things with. The ones in this paragraph, for example, it will ignore. The recognition sequence is <code>`@</code> to begin a magic word, and <code>@`</code> to end one. </p>

<p>These aren&#39;t macros. As you can see, they remain in the source code, and don&#39;t modify it.</p>

<p>Adding <code>[instaparse &quot;1.2.2&quot;]</code> to our project.clj gives us this:</p>

<p><code>@/marmion/athena/project.clj@</code> &#8211;&gt; where we find it, natch</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">defproject </span><span class="nv">athena</span> <span class="s">&quot;0.1.0-SNAPSHOT&quot;</span>
</span><span class='line'>  <span class="ss">:description</span> <span class="s">&quot;Athena: a Weaver of Code&quot;</span>
</span><span class='line'>  <span class="ss">:url</span> <span class="s">&quot;http://github.com/mnemnion/marmion/athena&quot;</span>
</span><span class='line'>  <span class="ss">:license</span> <span class="p">{</span><span class="ss">:name</span> <span class="s">&quot;BSD 2-Clause License&quot;</span>
</span><span class='line'>            <span class="ss">:url</span> <span class="s">&quot;http://http://opensource.org/licenses/BSD-2-Clause&quot;</span><span class="p">}</span>
</span><span class='line'>  <span class="ss">:dependencies</span> <span class="p">[[</span><span class="nv">org.clojure/clojure</span> <span class="s">&quot;1.4.0&quot;</span><span class="p">]</span>
</span><span class='line'>                 <span class="p">[</span><span class="nv">instaparse</span> <span class="s">&quot;1.2.2&quot;</span><span class="p">]])</span>
</span></code></pre></td></tr></table></div></figure>

<p>Which should compile. </p>

<p>Lein provides us with the following template in <code>@/marmion/athena/src/athena/core.clj@</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">ns </span><span class="nv">athena.core</span>
</span><span class='line'>    <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">instaparse.core</span> <span class="ss">:as</span> <span class="nv">insta</span><span class="p">]))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">foo</span>
</span><span class='line'>  <span class="s">&quot;I don&#39;t do a whole lot.&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">x</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">println </span><span class="nv">x</span> <span class="s">&quot;Hello, World!&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>

<p>We added instaparse.core there. This should compile too. </p>

<p>We now have a powerful and general [GLL] parser at our disposal. Yippie!</p>

<p>Let&#39;s do something with it!</p>

<p>How about we open up our source file, <code>athena.md</code>, and see if we can produce a quine of our existing file and directory structure?</p>

<p>Leiningen provides us with a test, <code>@/marmion/athena/src/athena/core_test.clj@</code>. It begins life looking like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">ns </span><span class="nv">athena.core-test</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:use</span> <span class="nv">clojure.test</span>
</span><span class='line'>        <span class="nv">athena.core</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">deftest</span> <span class="nv">a-test</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">testing</span> <span class="s">&quot;FIXME, I fail.&quot;</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">is</span> <span class="p">(</span><span class="nb">= </span><span class="mi">0</span> <span class="mi">1</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>

<p>We will leave it alone for now. Eventually, we will want to test our quine against the code as it was written. </p>

<p>For the same reason, we will leave the function <code>foo</code> in the namespace. Nothing will be deleted or modified, and the order in which code is introduced is the order into which it will be woven. This is a bootstrap, after all. </p>

<p>Instaparse has its own format, which could be specified as a string within the .clj file. We prefer to put the grammar in its own file, <code>@/marmion/athena/zeus.grammar@</code>, which we start like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>(* A Grammar for Zeus, Father of Athena, A Literate Weaver *)
</span></code></pre></td></tr></table></div></figure>

<p>Our first rule is top level. The markdown may be separated into that which is kept, that which is ignored, and that which is magic.</p>

<p>In Instaparse, that looks something like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>zeus-program = (magic | code | &lt;markdown&gt;) *
</span></code></pre></td></tr></table></div></figure>

<p>What this says is that a zeus program is any combination of magic, code, and markdown. Since Zeus does nothing with the markdown, we use angle brackets to tell Instaparse that we don&#39;t care to see the output. </p>

<p>We&#39;ll define code next:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>code =  &lt;&quot;`&quot; &quot;`&quot; &quot;`&quot;&gt; code-type code-block+ &lt;&quot;`&quot; &quot;`&quot; &quot;`&quot;&gt;
</span><span class='line'>   | &lt;&quot;`&quot; &quot;`&quot; &quot;`&quot;&gt; &quot;\n&quot; code-block+ &lt;&quot;`&quot; &quot;`&quot; &quot;`&quot;&gt;
</span><span class='line'>   ;
</span><span class='line'>
</span><span class='line'>code-type = &quot;clojure&quot; | &quot;text&quot; ;
</span><span class='line'>
</span><span class='line'>&lt;code-block&gt; = #&#39;[^`]+&#39; | in-line-code ;
</span><span class='line'>
</span><span class='line'>&lt;in-line-code&gt; = !(&quot;`&quot; &quot;`&quot; &quot;`&quot;) (&quot;`&quot;|&quot;``&quot;);
</span></code></pre></td></tr></table></div></figure>

<p>Which will suffice to capture our quine. </p>

<p>Please note: we could use a more direct way to capture three <code>`</code>, if we weren&#39;t writing a peculiar quine. Zeus uses the simplest possible grammar to extract a minimalist weaver from this very source file. </p>

<p>A couple notes: <code>code-block</code> is mostly a regular expression that doesn&#39;t consume backticks. <code>in-line-code</code> uses negative lookahead <code>!</code>, which is great stuff: it says, if there aren&#39;t three backticks ahead of us, you may match one or two of those backticks. </p>

<p>Between them, they match everything except three backticks. Real Markdown uses newlines and triple backticks together. This is harder to write and understand, so we&#39;ll do it in the second pass.</p>

<p>We also need magic:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>&lt;magic&gt; = &lt;&quot;`@&quot;&gt; magic-word &lt;&quot;@`&quot;&gt; ;
</span><span class='line'>
</span><span class='line'>magic-word = #&#39;[^@]+&#39; ;
</span></code></pre></td></tr></table></div></figure>

<p>Which is defined fairly carefully to consume our magic words. We don&#39;t use the at-sign elsewhere in the outer Markdown to enable easy magic.</p>

<p>That leaves <code>markdown</code> which is perhaps not strictly named, since the code blocks are markdown also. For Zeus, we may as well call it junk; we have to match it, but we don&#39;t look at it. It looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>markdown = #&#39;[^`@]+&#39; | in-line-code;
</span></code></pre></td></tr></table></div></figure>

<p>We&#39;re done! We now have a grammar that we can make into a parser, so let&#39;s do it: we need to add more code to <code>@/marmion/athena/src/athena/core.clj@</code>. </p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">zeus-parser</span> <span class="p">(</span><span class="nf">insta/parser</span> <span class="p">(</span><span class="nb">slurp </span><span class="s">&quot;zeus.grammar&quot;</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>

<p>That was simple enough. It disguises the toil of repeatedly writing bad, useless and exponentially explosive grammars.</p>

<p>But then, literature generally hides the messiness behind its production. If you have read the unedited <em>Stranger in a Strange Land</em>, which Heinlein never wanted published, you can see why. Presuming you&#39;ve read the edited version. </p>

<p>Now, we use <code>zeus-parser</code> to parse this document, <code>athena.md</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">parsed-athena</span> <span class="p">(</span><span class="nf">zeus-parser</span> <span class="p">(</span><span class="nb">slurp </span><span class="s">&quot;athena.md&quot;</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>

<p>When we run <code>core.clj</code> in a REPL, we see that <code>parsed-athena</code> is a tree-structure containing our magic words and code. We&#39;ve designed this puzzle so that we can use this sorted information in the order we found it, so we don&#39;t need the tree structure.</p>

<p>To simply get rid of the tree structure we would <code>flatten</code> it. But this would leave us in a bad way, because some of our code blocks aren&#39;t globbed into a single string, thanks to separate detection for <code>` `</code> [sic] and <code>`</code>. </p>

<p>Fortunately, this is so common that Instaparse ships with a function for fixing it. <code>insta/transform</code> to the rescue!</p>

<p>First we need a helper function for insta/transform to call:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">cat-code</span> <span class="s">&quot;a bit of help for code blocks&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">tag</span> <span class="o">&amp;</span> <span class="nv">body</span><span class="p">]</span> <span class="p">(</span><span class="nf">vec</span> <span class="p">[</span><span class="nv">tag</span> <span class="p">(</span><span class="nb">apply str </span><span class="nv">body</span><span class="p">)]))</span>
</span></code></pre></td></tr></table></div></figure>

<p>Then we call it and do some stuff to the results:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">flat-athena</span> <span class="p">(</span><span class="nb">drop </span><span class="mi">10</span> <span class="p">(</span><span class="nf">flatten</span> <span class="p">(</span><span class="nf">insta/transform</span> <span class="p">{</span><span class="ss">:code</span> <span class="nv">cat-code</span><span class="p">}</span> <span class="nv">parsed-athena</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>

<p>Now, how you feel about this line depends on how you feel about Lisp, generally. This was written progressively from the middle out, on a REPL. It&#39;s easy to read if you know that, and would be easier still if formatted more naturally. </p>

<p>A more idiomatic Clojure way to do all this would be to use a threading macro like <code>-&gt;&gt;</code> to thread the data structure through the transformations, instead of making all these global defs. Everything so far could be a single function, though it&#39;s sensible to put the parser in its own ref.</p>

<p><code>drop 10</code> just gets us past the front matter. We introduce our idioms before we use them, for a reason.</p>

<p>We now have a flat vector, containing all the information we need. We need to transform it into a data structure which may then be massaged and spat out as our original project and core files. </p>

<p>The quine could be completed with a trivial act, which we put in the margins: <code>(spit athene-as-is.md (remove-tags-flatten-and-concatenate (zeus-parser (slurp athena.md) :unhide :all)))</code>, which calls a function we needn&#39;t bother to write. All this does is parse athena.md, remove the tags, flatten the remaining literal values, which, because we used <code>:unhide :all</code>, was everything from our original source file. Cute, but not interesting enough to belong in the quine. Opening your source file, doing nothing interesting to it, and saving/printing it is generally a trivial quine, though if the convolutions you put the text through are hard enough to follow you will amuse someone at least.</p>

<p>Instead, let&#39;s write a little helper function, <code>key-maker</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">key-maker</span>
</span><span class='line'>  <span class="s">&quot;makes a keyword name from our file string&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">file-name</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">keyword </span> <span class="p">(</span><span class="nb">last </span><span class="p">(</span><span class="nf">clojure.string/split</span> <span class="nv">file-name</span> <span class="o">#</span><span class="s">&quot;/&quot;</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>

<p>This takes our fully-qualified filename, pulled from a magic word, and keywordizes it. The magic words are arranged so there&#39;s one each time zeus needs to change files.</p>

<p>Now for the meat of the matter. <code>weave-zeus</code> produces the source file to zeus from the markdown version of this very file. </p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">weave-zeus</span>
</span><span class='line'>  <span class="s">&quot;a weaver to generate our next iteration&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">state</span> <span class="nv">code</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">keyword? </span><span class="p">(</span><span class="nb">first </span><span class="nv">code</span><span class="p">))</span>
</span><span class='line'>      <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">= </span><span class="ss">:magic-word</span> <span class="p">(</span><span class="nb">first </span><span class="nv">code</span><span class="p">))</span>
</span><span class='line'>          <span class="p">(</span><span class="nf">weave-zeus</span> <span class="p">(</span><span class="nb">assoc </span><span class="nv">state</span>
</span><span class='line'>                             <span class="ss">:current-file</span>, <span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nb">rest </span><span class="nv">code</span><span class="p">)))</span>
</span><span class='line'>                      <span class="p">(</span><span class="nb">drop </span><span class="mi">2</span> <span class="nv">code</span><span class="p">))</span>
</span><span class='line'>          <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">file-key</span> <span class="p">(</span><span class="nf">key-maker</span> <span class="p">(</span><span class="ss">:current-file</span> <span class="nv">state</span><span class="p">))]</span>
</span><span class='line'>              <span class="p">(</span><span class="nf">weave-zeus</span> <span class="p">(</span><span class="nb">assoc </span><span class="nv">state</span>
</span><span class='line'>                                 <span class="nv">file-key</span>,
</span><span class='line'>                                 <span class="p">(</span><span class="nb">apply str </span><span class="p">(</span><span class="nf">state</span> <span class="nv">file-key</span><span class="p">)</span> <span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nb">rest </span><span class="p">(</span><span class="nb">rest </span><span class="nv">code</span><span class="p">)))))</span>
</span><span class='line'>                          <span class="p">(</span><span class="nb">drop </span><span class="mi">3</span> <span class="nv">code</span><span class="p">))))</span>
</span><span class='line'>      <span class="nv">state</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>

<p>Now, that&#39;s a hack. It&#39;s a bootstrap; I fiddled with it until it worked. It is perhaps more readable than a more elegant version, if you have, like most of us, a background or ongoing investment in imperative style. The principle is ruthless pruning and minimal intelligence. We aren&#39;t touching it further, though we use it as a spring-off point for migraine, the next step in the process.</p>

<p>Migraine because it actually gives birth to Athena. Named in honor of whichever poor sufferer dreamed that mythos up. </p>

<p>So we move the latest athena.md into the project directory, load up the REPL and sure enough, it&#39;s all in there. Now we just have to <code>spit</code> it out. To do it right, we&#39;d have kept some exact record of our file name so we could put it into a new directory of the same form. We&#39;re going to cheat instead; we did the hard part, and want to keep it readable since we don&#39;t have macros with which to bury the boring parts.</p>

<p>So here&#39;s our last trick:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">zeus-map</span> <span class="p">(</span><span class="nf">weave-zeus</span> <span class="p">{}</span> <span class="nv">flat-athena</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">do </span><span class="p">(</span><span class="nf">spit</span> <span class="s">&quot;migraine/zeus.grammar&quot;</span>  <span class="p">(</span><span class="ss">:zeus.grammar</span> <span class="nv">zeus-map</span><span class="p">))</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">spit</span> <span class="s">&quot;migraine/core-test.clj&quot;</span> <span class="p">(</span><span class="ss">:core_test.clj</span> <span class="nv">zeus-map</span><span class="p">))</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">spit</span> <span class="s">&quot;migraine/core.clj&quot;</span>      <span class="p">(</span><span class="ss">:core.clj</span> <span class="nv">zeus-map</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>

<p>That&#39;s it! The structure of the migraine directory is flat, not the structure leiningen requires, and there are some extra newlines in the source, but I don&#39;t care and neither should you. It&#39;s officially close enough for government work. In our next chapter, we will undergo the formality of writing a test and demonstrating that Migraine&#39;s markdown contains Athena alpha, which will be a part of Athena herself. </p>

<p>Migraine, the next chapter in this adventure, will add some actual capabilities. Migraine is just Zeus with an extra headache: instead of producing himself, he has to produce Athena, which is a more challenging software to write.   </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Progressive Refinement in GLL]]></title>
    <link href="http://mnemnion.github.io/blog/2013/08/04/progressive-refinement-in-gll/"/>
    <updated>2013-08-04T14:24:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/08/04/progressive-refinement-in-gll</id>
    <content type="html"><![CDATA[<p>The <a href="http://dotat.at/tmp/gll.pdf">GLL Algorithm</a> is one of those core concepts that can change how we do computation. It&#39;s phenomenally powerful. I believe we&#39;re just starting to see what it&#39;s capable of.</p>

<p>I plan to implement GLL, as soon as some of the support work is done. It&#39;s going to be a somewhat leisurely task. I&#39;m taking a lot of notes. Currently, I&#39;m using <a href="https://github.com/Engelberg/instaparse">Instaparse</a> to play around with the algorithm.</p>

<p>It&#39;s fantastic stuff, much more flexible as an idiom than, say, ANTLR. It is also much easier to write yourself into an exponential corner, and I find myself abusing regular expressions somewhat rather than torturing the grammar in other ways. </p>

<p>I think this is a consequence of GLL&#39;s strengths, which allow it to parse out well over data that is already in a nested structure. Using it for a shallower kind of pattern matching kills performance even in parallel execution, because at any point in matching a long string of related structures, it could encounter a context that would kill the whole chain of inquiry. If there is any possibility of ambiguous matching, this explodes even faster. </p>

<p>An example of this kind of use is parsing a bunch of sentences and paragraphs into text, which is words and whitespace. Except if you encounter a special character you have to switch context completely; this last requirement makes most natural ways of writing the grammar fail. </p>

<p>An alternative would be progressive refinement. In Instaparse, the latest definition of a rule is used, and all earlier rules are ignored. My proposal, which I intend to use in my own work, is that multiple definitions of the same rule are tried sequentially against the data, after a successful parse.</p>

<p>This would damage the arbitrarily-ordered nature of Instaparse grammars, in a sense. Instaparse still has to decide what to do with multiple definitions, and currently uses the last one provided. </p>

<p>This would just formalize something one can already do with Instaparse, which is to parse a string, flatten the area of interest back into a string, and re-parse that string into a new rule. Substitute your new parse for the old one (this is very easy), and you&#39;ve done it.</p>

<p>Automating that into the grammar would allow one to grab large globs of identical data, switching context when necessary, then parse that data into shape in smaller pieces that don&#39;t have to worry about context boundaries. </p>

<p>It&#39;s a straightforward adaptation, being properly speaking a composition of the same function, <code>insta/parse grammar</code>, over a subset of the data returned by the first call. </p>

<h2 id="toc_7">Automated profiling</h2>

<p>One neat thing about grammars is that you can run them backwards to generate compliant gibberish. As you&#39;d expect, given the vast difference in magnitude between the set of valid input of a given length and the set of all input of that same length, it is quick to use Markov type rules to generate babble for even an intricate, ambigous grammar that would blow up trying to validate the output.</p>

<p>In fact, that&#39;s the point. One may envision, and I may even write, a tool that uses pseudorandom walks to generate longer and longer streams of valid gibberish, and try them against the grammar, looking for suspicious jumps in speed or number of possible parses. Even a naive tool, running on a remote server, would generate useful information while developing a parser. One may envision the tool dialing in where parses go ambigous, generating input accordingly, and alerting the user, or doing the same for square and cubic factors that show up.</p>

<p>If the validity of the babble is questionable, then one has identified permission within the grammer that one may wish to eliminate. It has potential.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Tangled Web We Weave]]></title>
    <link href="http://mnemnion.github.io/blog/2013/08/03/a-tangled-web-we-weave/"/>
    <updated>2013-08-03T11:13:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/08/03/a-tangled-web-we-weave</id>
    <content type="html"><![CDATA[<p><a href="http://www-cs-faculty.stanford.edu/%7Euno/lp.html">Literate Programming</a> is one of those paradigms whose fate is continual reinvention. I&#39;ve been noticing that my software projects start as Markdown. It stands to reason that they should end up as Markdown as well.</p>

<p><a href="https://help.github.com/articles/github-flavored-markdown">Git Flavored Markdown</a>, in particular, is crying out for a literate, multi-model programming system. The mechanism of named fenced code blocks lets one put multiple languages in a single file, and they will already be syntax highlighted according to the named language. </p>

<p>As literate programming is for the ages, we shall call our system <a href="README.md">Marmion</a>. The weaver shall be known as <a href="athena.md">Athena</a>; the tangler, <a href="">Arachne</a>.</p>

<p>If at all possible, we don&#39;t want to touch GFM itself. Therefore, here are some principles:</p>

<ul>
<li><p>Code in fenced code blocks is extracted, macro-expanded, and executed in whatever ways are appropriate.</p></li>
<li><p>Macros must employ patterns not used in a given language; therefore, we must be able to define those patterns.</p></li>
<li><p>All configuration happens in special code blocks, called <code>```config</code>:</p></li>
</ul>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class="p">{</span> <span class="ss">:name</span> <span class="s">&quot;A config file&quot;</span>,
</span><span class='line'>  <span class="ss">:format</span> <span class="ss">:edn</span>
</span><span class='line'>  <span class="ss">:magic-number</span> <span class="mi">42</span> <span class="p">}</span> <span class="c1">;this is actually tagged ```clojure</span>
</span></code></pre></td></tr></table></div></figure>

<ul>
<li><p>Code in regular unfenced code blocks is not included in the weave. Nor are fenced code blocks that aren&#39;t reached from the top macro. The code above, for example, <em>will not</em> be in the finished weave, because it is exemplary.</p></li>
<li><p>All text ends up in the tangle, which is an HTML file. No other tangle format is contemplated. </p></li>
<li><p>If standardized, the tangle format will not be specified, only the markup format and the requirements for the subsequent weave. HTML is a moving target, as is visual display in general. </p></li>
<li><p>The Markdown may be extended, but only in the same way as any other code: by specifying a macro template and expanding it from provided code. It is the macro-expanded Markdown which is tangled and woven.</p></li>
<li><p>Corollary: the Markdown is macro expanded before anything in a code block.  </p></li>
<li><p>Corollary: the Markdown macro will be standard. There should be no reason to include it. Because Clojure is the implementation language, and has a defined reader macro syntax, this is already true of Clojure(Script).</p></li>
<li><p>The weaver should visit all internal links in search of code. Some tag in HTML form should be provided so that fully-marked-up links, so tagged, will also be followed in search of exterior code. </p></li>
<li><p>If exterior code is requested, it is added to the source as a fenced code block. The tangle will preserve the link directly above the code block. Some sensible effort will be made to infer the code format from the file extension. This is to be done before macro expansion, so that if there are macros in the exterior code, they will be expanded.</p></li>
<li><p>We should maintain a set of canonical macro patterns for languages, to encourage mutual compatibility in source and tangled code.</p></li>
<li><p>No mechanism for transclusion on the file level will be provided. The file structure of the Markdown is the file structure of the tangle. Working around this using the tagged-link method will leave a broken link in your tangle.</p></li>
</ul>

<p>This is the sort of project that we can tackle in stages. The most important part is the weaver, because we have a fine tangler in the form of <a href="http://jekyllrb.com/">Jekyll</a>. </p>

<p>This is a job for <a href="http://clojure.org">Clojure</a>. The weaver and perhaps the tangler will be Clojurescript compatible in the narrow sense, but useless unless Instaparse is ported, which seems unlikely, though you never know. </p>

<p>Clojure is chosen for a few reasons. <a href="https://github.com/edn-format/edn">EDN</a>, for one, which will be the format of any <code>```config</code> code block. Also because of <a href="https://github.com/Engelberg/instaparse">Instaparse</a>, for which the usual regular-expression based markup approach is a strict subset of capabilities. It has the best story I&#39;m aware of for setting regular expressions declaratively in a data format, which is exactly how we will provide macros. </p>

<p>To be clear, this will let us syntax highlight a provided macro in a distinctive way, and put things like the colors to use right in the markdown. This is only useful with a completed weaver; Pygments will get the macros wrong but this is a minor stylistic matter which can be corrected by retangling with a better highlighter. </p>

<p>Instaparse is my go-to choice for writing flexible parsers that are meant to be shared, so Clojure it is. I hope Instaparse catches on to the point where it becomes core, and hence worth maintaining separate <code>.clj</code> and <code>.cljs</code> versions. </p>

<p>The first, and most important step, is writing <a href="athena.md">Athena</a>, the weaver. The weaver does the following: finds all the <code>```config</code> code, parses it to configure itself, then goes after the code blocks, and uses the macros and config information to construct the weave. Finally, it calls the trigger file, which must contain everything needed to build the weave into an executable, or whatever the final product is.</p>

<p>The tangler, <a href="">Arachne</a>, should be a <a href="https://github.com/mnemnion/jekyll">fork of Jekyll</a>, with a low surface area of interaction. What I mean by this is that merges between the bases should avoid touching one another&#39;s files wherever possible. The only changes I contemplate personally is to plug-replace the syntax highlighter, for several reasons. </p>

<p>Pygments requires one to write actual code to markup a new format. This is distasteful. Also, we need to markup the macros, which we won&#39;t know until we weave the code. Furthermore, a static syntax highlighter should be based on a powerful parser, not a regular engine janked up with extra Python. </p>

<p>If Marmion becomes popular, someone might want to write advanced capabilities: putting compatible code in a REPL, for example, or linking to one from the code, or linking to the <a href="https://github.com/mnemnion/emojure/blob/master/src/emojure/core.clj#L7">line number</a> in a public Github repository generated by the weaver. The last is particularly powerful. All of this will assuredly be easier with a parser-backed tangler. </p>

<p>This is the only way I have to tackle large problems: recursing through the Big Project until I hit something atomic and critical to further progress. Arc leads to GGG, which will benefit greatly from a literate style, which leads to Marmion. Marmion built, writing GGG in an understandable way becomes possible. </p>

<p>I think I&#39;ve painted myself into a corner, as I can&#39;t think of anything offhand which I need to write in order to write Marmion. </p>

<p>Time to generate more Markdown!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Syntax for Literal Strings]]></title>
    <link href="http://mnemnion.github.io/blog/2013/07/27/syntax-for-literal-strings/"/>
    <updated>2013-07-27T10:09:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/07/27/syntax-for-literal-strings</id>
    <content type="html"><![CDATA[<p>I find it somewhat astonishing that the languages with which I&#39;m familiar still start and end strings with the same character. It is as though we used <code>|</code> for <code>{</code> and <code>}</code> in code blocks and relied on context to figure out if it was <code>begin</code> or <code>end</code>. </p>

<p>Incidentally, it&#39;s quite possible to write a language this way, and an interesting exercise. <code>for | i = 0 ; i &lt; 2 ; i++ || codeBlock |</code> should parse just fine. Heaven help you if you misplace anything. </p>

<p>Check out <a href="https://en.wikipedia.org/wiki/Delimiter#Bracket_delimiters">bracket delimiters</a> on the Wiki. Two of these things are not like the others. Those two are used preponderantly for strings. </p>

<p>It&#39;s clear enough how it happened. A string has an obvious mapping to literary quotation: <code>&quot;That&#39;s what she said!&quot;</code>.  ASCII gives us exactly three options: <code>&#39;</code>, <code>`</code>, and <code>&quot;</code>. <a href="http://c-programming.itags.org/q_c-programming-language_16297.html">It turns out</a> that C was defined using 91 characters, and <code>`</code> was not among them. </p>

<p>Meta enough, I&#39;m writing this in Markdown, and to type <code>`</code>, I must type <code>`` ` ``</code>. I will leave how I typed <code>`` ` ``</code> as an exercise for the reader. </p>

<p>So C chose <code>&quot;</code> for string syntax, and <code>&#39;</code> for characters, and these decisions made sense, somewhere in the mists of time. C also initiated the proud tradition of string escaping, which wasn&#39;t invented to get around the delimiter problem, but which can be used for that purpose in a hacky way. String escaping is so you can say <code>\n</code> and get a newline, the incidental benefit is you can say <code>\&quot;</code> and get a <code>&quot;</code>, hence one may include any character in such a string. Two backslashes is of course <code>\\\\</code>. One gets used to it. </p>

<p>Oh hey, just for fun, why not write a regex that will match such strings? Won&#39;t take you long, I promise. I&#39;ll be right here!</p>

<p>To the point. In typography, we don&#39;t do this. We start quotations with <code>“</code> or <code>‟</code> and end them with <code>”</code>. On the <a href="http://en.wikipedia.org/wiki/%C2%AB">Continent</a>, <code>«</code> and <code>»</code> are used, and this would be my preference as they are much easier to tell apart and don&#39;t have two choices for the opening delimiter. If you follow the link, It turns out they are used both <code>«this way»</code> and <code>»this way«</code> and even <code>»this way»</code> by Finns (<a href="http://en.wikipedia.org/wiki/Finnish_language">of course</a>). We favor the first, because all other brackets in computer programming are inward facing <code>&lt;{[(like so)]}&gt;</code>.</p>

<p>What&#39;s the point? They aren&#39;t on standard keyboards in the US; while any worthwhile editor can get around this, there&#39;s a pain point there. Some people will argue a virtue in using ASCII for source code, and while those people <a href="https://github.com/cgyarvin/urbit">have a point</a>, the ship sailed a long time ago. We use Unicode, and it isn&#39;t going anywhere. </p>

<p>The point is that, without proper left-right matched strings, you cannot literally quote your own source code within your source code. This is damaged, for any language that lets you evaluate at runtime (the interesting ones IOW). If we use <code>«</code> and <code>»</code>, we can use bog-standard reference counting to assure that any properly-balanced literal strings in the source code get quoted. Since in this imaginary syntax a bare <code>»</code> not balanced on the left with a <code>«</code> is a syntax error, any correct program can be embedded. </p>

<p>If, for any reason, you need a bare <code>»</code>, why not use the ISO standard SHA-1 hash of the Unicode value of <code>»</code>? Why not indeed. It then becomes impossible to literally quote that one hash, which is officially the point where it is perverse to pursue the matter further. Concatenate for that one. </p>

<p>To be clear, <code>&quot;</code> for escaped strings is concise and well understood, and with enough convolutions one may write as one pleases. It&#39;s syntax such as <code>&#39;&#39;&#39;</code> for literal strings that grates against my sensibilities. </p>

<p>Clojure has no syntax for literal, multi-line, unescaped strings. That&#39;s too bad; no one does syntax like Rich Hickey, and I suspect that the inadequacy of existing options plays a role here. He may not be willing to go off-keyboard, but I feel that the <code>«</code> and <code>»</code> syntax has a lot to offer. Certainly Europeans would be pleased. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Homoiconicity and Data Forms]]></title>
    <link href="http://mnemnion.github.io/blog/2013/06/17/homoiconicity-and-data-forms/"/>
    <updated>2013-06-17T14:52:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/06/17/homoiconicity-and-data-forms</id>
    <content type="html"><![CDATA[<h3 id="toc_6">Representation of Data in Structured Programs.</h3>

<p>Today we&#39;re going to discover a programming language. We&#39;re going to start by contemplating the idea of code as data. </p>

<p>LISP, and by the all-caps I mean the original flavours, had two fundamental forms: atoms, and lists. As Lisp grew up, the lists became able to represent any sort of data type, but at the expense of a certain homoiconicity. </p>

<p>That&#39;s a controversial assertion, but hear me out. A list in a Lisp is a bunch of cons cells, it&#39;s a specific data structure used by default to do pretty much anything. Since the first position (first second third) has a function or a macro, you can fake, say a hash, by saying something like (hash a a-prime b b-prime) but here&#39;s the problem: that&#39;s not homoiconic to your data anymore. Not in a way that accords with modern expectations. </p>

<p>Let&#39;s talk about JSON. Now, JSON is homoiconic to your data. <code>{}</code>? Object. <code>[]</code>? List. <code>&quot;&quot;</code>? String. <code>(1-9)(digits*)</code>? Number. And so on. </p>

<!-- more -->

<p>What makes this homoiconic, and Lisp less so? Strictly, it&#39;s that by the time you reach the data, you know what type of data it is. Before you get to the value of a string, you see the <code>&quot;</code>, before you get to an object, you see <code>{</code>, and so on. In paren-only Lisps, you see <code>(</code>, think &quot;list&quot;, then see a &quot;function&quot;, discover that it&#39;s actually &quot;hash&quot;, and reparse the whole thing as a new data type. This has a cost that adds up over time. Also, the data type is closed exactly like a list, which it isn&#39;t, so finding the close character in a sea of  parentheses is genuinely hard &#8211; though in Lisp, this matters less in practice than one might think.</p>

<p>CL heads will staunchly and indignantly deny all this, and they&#39;re probably right for them: there are reader macros, paren bashing is a totally valid way to close structured data, and so on. But it&#39;s just not how we&#39;d do it now. So let&#39;s start with this JSON business and think through how we&#39;d make a language from it.  </p>

<p>JSON is extracted from JavaScript, of course, so we could just add JavaScript back and call it a day. That&#39;s not the point of this exercise, the point of this exercise is to make a JSONian language from JSON. JSON is JavaScripty, but JavaScript is not JSONian. </p>

<p>We&#39;ll add bare words back first. JSON supports only quoted strings, because JS uses bare symbols for all variables including functions, and JSON isn&#39;t supposed to be able to pass you executable code. But JSONian is all about executable code, so let&#39;s start by putting them back.</p>

<p>But put them where? Inside curly braces? Right now, <code>{ &quot;foo&quot; : &quot;bar&quot; }</code>is what we&#39;re doing with curly braces. In JS that&#39;s a special form, the more normal use of curlies is <code>{ statement; statement; statement; }</code>. Do we want to allow that? </p>

<p>From the JSONian perspective, this would be confusing syntactic overloading. Also, parentheses are not used yet. So we&#39;ll do the Lispy thing, and use them for <code>(function arg arg arg)</code>. It&#39;s simple, and that&#39;s a virtue in a data representation format. Also, unlike Lisp, it will be much less overloaded, because we have <code>[list, list, list]</code> for lists. But let&#39;s call them vectors now, since we now have Lispy lists and don&#39;t want to get confused. </p>

<p>Let&#39;s also wave a magic wand and get rid of some strictures we don&#39;t need. No commas between list elements, no colon between key : value pairs. They aren&#39;t strictly necessary, as list elements are already separated by whitespace and objects won&#39;t compile if they have an odd number of elements. Let&#39;s be nice and let you add commas wherever you want, if it helps you keep track of something. Our language will ignore them.</p>

<p>Furthermore, let&#39;s get rid of the silly strictures on numbers and just say that, to a first approximation, they behave like actual mathematical numbers. It might be nice to add imaginary/complex, but let&#39;s stay grounded: integers, rationals and reals. </p>

<p>Are we done? We could be; this would be a fine language. But let&#39;s refine. One place we can improve: symbols need to resolve to something else or it&#39;s an error, while strings are opaque to the language, that is, the contents of a string is not meaningful to the compiler itself and we don&#39;t want to change that. A compiler won&#39;t know that &quot;foo&quot; isn&#39;t &quot;bar&quot; unless you compare them explicitly. Since we have a convenient colon left over from trimming the fat off our objects (let&#39;s just call them maps, since they are), we can define <code>:foo</code> and <code>:bar</code> as keywords, which always equal themselves. They&#39;re useful in our maps: <code>{:a a :b b}</code> could let us do something like <code>(:a {:a a :b b})</code>, where our keyword acts like a function and retrieves the <code>:a</code> value from the map. <code>(&quot;a&quot; {&quot;a&quot; a &quot;b&quot; b})</code> should be an error, because it makes no sense to &quot;literal string&quot; something. However, there&#39;s no particular reason to restrict the key or value types of our maps, merely the use of this particular syntax sugar. </p>

<p>I could keep being coy, but that&#39;s not the point: this is Clojure, and this is why I think it&#39;s phenomenal and am convinced that Clojure is the branch from which all future Lisps of importance and duration will grow. </p>

<p>Being homoiconic to your primary data types is important, I dare say crucial. For LISP, that was atoms and lists, and for its descendants that are not Clojure, this fundamental duality is expressed in the syntax. </p>

<p>For FORTH, that is atoms and words. FORTH is also good stuff, but pg isn&#39;t out there telling you to learn it. Maybe he should, we would get a lot of very reliable and hackable embedded systems in the bargain. </p>

<p>But the verdict is in: certain data types are just fundamental and we like having syntax that reflects this. Consider <code>$$$ foo bar baz bux $$$</code>, where <code>$$$</code> is our separator so that we don&#39;t get any hints. </p>

<p>Is that a list, such that adding some <code>qux</code> will give <code>$$$ qux foo bar baz bux $$$</code> ? Is it a vector, such that adding <code>qux</code> gives <code>$$$ foo bar baz bux qux $$$</code>?<br>
Perhaps a map, where adding qux wouldn&#39;t make sense, but adding <code>$$$ qux quux $$$</code> would give <code>$$$ foo bar, baz bux, qux quux $$$</code>? Or is it a set, where adding qux would give <code>$$$ foo qux baz bux bar $$$</code> (as an example order) but adding another foo would do nothing?</p>

<p>In J. Random Lisp, this is easy: <code>(vec foo bar)</code> <code>(map foo bar)</code> <code>(set foo bar)</code>. Or wait, does map make a map or map a function over some values? Maybe it&#39;s hash, or wait, does hash create a SHA? Arse, where&#39;s my documentation? I think set dynamically binds argument one to argument two&#8230;. </p>

<p>In Clojure, this is <code>(list foo)</code> <code>[vector foo]</code> <code>{:map foo}</code> <code>#{set foo}</code>. There are parenthetical forms of all of them, if necessary. </p>

<p>Note that these are not type categories. If you need that kind of thing, there&#39;s Haskell. These are <em>form</em> categories. There are only so many ways to use linear order to represent data, and Clojure&#39;s set of those is, as far as I can determine, exhaustive. Since linear order is all we have as long as we&#39;re making our programs out of strings, we now have the right amount of expressive power, for my taste. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Introduction to Ent]]></title>
    <link href="http://mnemnion.github.io/blog/2013/06/17/an-introduction-to-ent/"/>
    <updated>2013-06-17T10:11:00-07:00</updated>
    <id>http://mnemnion.github.io/blog/2013/06/17/an-introduction-to-ent</id>
    <content type="html"><![CDATA[<p>ent is a new approach to code creation. It is (will be) an editor and library that works on parse trees, rather than on files, and registers all changes as <a href="http://www.codecommit.com/blog/java/understanding-and-applying-operational-transformation">operational transformations</a>. It does so through the medium of familiar code files, but these may be thought of as an interface to the code, and as a product of it, similar to the executable binaries produced by a compiler. </p>

<h3 id="toc_0">Parse Aware Editing of Structured Files</h3>

<p>ent&#39;s major rationale is parse-awareness. It will, in general, not allow you to type invalid code, though this can always be overridden. It will parse your code as you create it, storing the resulting file as a series of operational transformations on the parse tree. As a language is more thoroughly defined within ent, this enables REPL-like instant feedback and sophisticated refactoring. </p>

<!-- more -->

<p>A simple example in json  will get us started. We are editing this file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>  <span class="p">{</span><span class="nt">&quot;foo&quot;</span><span class="p">:</span><span class="s2">&quot;bar&quot;</span><span class="p">},</span>
</span><span class='line'>   <span class="err">_</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>

<p>Where <code>_</code> represents the cursor. We type <code>{</code>. </p>

<p>Because we are in an Array context, and the only rule that can match <code>{</code> is Object, we get:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>  <span class="p">{</span><span class="nt">&quot;foo&quot;</span><span class="p">:</span><span class="s2">&quot;bar&quot;</span><span class="p">},</span>
</span><span class='line'>   <span class="p">{</span><span class="err">_:**</span><span class="p">}</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>

<p>where <code>**</code> represents the target, which is the next place that ent expects us to move. </p>

<p>We now type <code>q</code>. Because we are in the Key context of an Object, this is not valid. But ent is friendly, so we get this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>  <span class="p">{</span><span class="nt">&quot;foo&quot;</span><span class="p">:</span><span class="s2">&quot;bar&quot;</span><span class="p">},</span>
</span><span class='line'>   <span class="p">{</span><span class="nt">&quot;q_&quot;</span><span class="p">:</span><span class="err">**</span><span class="p">}</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>

<p>Since json expects a string, the <code>&quot;&quot;</code> would actually be auto-inserted after the <code>{</code>. This example was somewhat contrived to show how ent can handle erroneous input through parse awareness.</p>

<p>Note, as an aside, that <a href="https://github.com/vmg/redcarpet">redcarpet&#39;s</a> json lexer identifies <code>**</code> as an error. This points to the advantage of parse aware editing, which can go far beyond syntax highlighting (as well as getting that task more correct than line-based regexes can).</p>

<p>We continue typing <code>ux</code> to give <code>qux</code>. Either <code>&quot;</code> or the right arrow key closes the string and gets us to our target:</p>

<p><figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span><br>
<span class='line-number'>2</span><br>
<span class='line-number'>3</span><br>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>  <span class="p">{</span><span class="nt">&quot;foo&quot;</span><span class="p">:</span><span class="s2">&quot;bar&quot;</span><span class="p">},</span><br>
</span><span class='line'>   <span class="p">{</span><span class="nt">&quot;qux&quot;</span><span class="p">:</span><span class="err">_</span><span class="p">}</span> <span class="err">**</span><br>
</span><span class='line'><span class="p">]</span><br>
</span></code></pre></td></tr></table></div></figure><br>
Note that the target has moved also.</p>

<p>All of this special magic is enabled by the fact that ent cooperates with a parser to parse, validate, and transform the file as you type. ent will also have a &#39;permissive&#39; mode where the user may make arbitrary changes to the file; upon returning to opinionated mode, ent will reparse the edited regions and try and make sense of the input. </p>

<p>This flavor of convenience is well known to IDE users; ent generalizes this, but aims to do so in a way that has deep and far-reaching implications. </p>

<h3 id="toc_1">Continuous Comprehension</h3>

<p>As programmers, we want to stay close to our code as we work with it. The move from batch processing to interactive compile-run cycles was a boon, and the development of REPLs took us further, but we remain in a state where we interact with mutable flat files. </p>

<p>We would like to be in a state where we interact with immutable trees that embody not only the state of our program&#39;s encoding, but every state the program has ever been in. Graphic designers and CAD technicians have had this for decades; one may take the typical Adobe Photoshop file and run it backwards to the very first edit.</p>

<p>What is holding us back is that flat files are the ubiquitous interface between tools in the programming chain, and they are mutable by default (indeed, to a fault). ent aims to do the least possible to allow the move to immutable tree-based code structure while maintaining flat files in a sensible state and allowing other tools to act on and transform those files as input into the code structure. </p>

<h3 id="toc_2">Deep Waters</h3>

<p>This is not a trivial move. If we were free to design our own ball game, we could start with immutable data types, define transformations on them, and start snowballing. </p>

<p>ent isn&#39;t that kind of project. The entire towering edifice of computer software is built on transacting mutable text files; with few exceptions, everything running has a canonical form as a collection of such files, which is interacted upon by various tools to generate the running code. </p>

<p>ent wants to thoroughly change the method for generating that collection. Current best practice is revision control; ent extends that to dizzying heights, so dizzying, in fact, that it uses existing version control to keep matters from getting totally out of hand. </p>

<p>To say that modern code bases are mutable text file collections is imprecise. In most cases, they are exactly that, backed by a revision control package such as git. This manages those aspects of history and difference which the user has decided to record, and is an improvement. </p>

<p>ent stores and understands the code base as a series of operational transformations on a parse tree, and treats flat files as the canonical interface to that parse tree. let&#39;s break that down some before we continue.</p>

<p>To the user, a flat file is exactly what it was before. ent allows you to do whatever you want to it, in permissive mode, and the restrictions of opinionated mode are there to help; the user experience we&#39;re going for is one of free typing, with transformations, reformatting, and opinions offered in real time. Trying to type syntactic nonsense won&#39;t work in opinionated mode, which is very much the point.</p>

<p>To ent, proper, edits on the flat file are not seen. ent tracks the cursor position within the parse tree, and reparses the input periodically (specifically when the cursor crosses rule boundaries). It is the result of those parsing actions that ent tracks and stores, as operational transformations on the code base itself.</p>

<p>That is the minimum necessary to interact with a flat file through ent: a parser which meets certain interface criteria and produces a parse tree that contains every character in the original file. We can add more, but we cannot have less.</p>

<p>Even a small amount of structure can be useful. If we divide English into words, sentences, and paragraphs, ent will keep track of each one of these entities as they come into existence, and allow us to do many of the fanciful things ent makes possible, such as correcting a typo in a way that propagates to multiple copy-pasted versions of a sentence. </p>

<p>Importantly, even a poor or ambiguous grammar will work, as long as the parser&#39;s output is deterministic. The guarantee that ent will make you is that any tree it makes, if walked from left to right, will give you your string back. </p>

<h3 id="toc_3">Branch and Merge</h3>

<p>Because ent uses operational transformation, it provides great flexibility and control in branching and merging. OT is used in products like Google Docs so that, if network problems cause two user edit streams to diverge, the edits can be merged automatically into a single canonical document as soon as connectivity is restored. </p>

<p>ent approaches OT differently. Where Docs etc. are concerned with synchronizing multiple versions of a single canonical file in near-real time, ent uses OT to flexibly handle multiple branches and merges of a single code base, which may be replicated elsewhere with optional differences. </p>

<p>It is the same underlying algorithm, and it leads to a substantially different approach to branching and merging than that embodied in programs like git. Ultimately, ent enables time travel; you may return to any point in the history of your project, make revisions and changes, and propagate them, with control, back to the front of the project.</p>

<p>Let&#39;s contrast this with git. In git, to make a branch, you tell git you want to make a branch. git takes a snapshot and starts tracking changes under a different name. If you revert to the original branch, it goes back to the snapshot and tracks a different set of changes. When you merge, if all goes well, all the changes from both branches are reflected in the new file structure.</p>

<p>With ent, the user does not have to decide to branch. They may simply rewind to the point where an alternate path is helpful, create it, and merge. If all goes well, you have a new reality, in which the old edits happened in the past. </p>

<p>That&#39;s why we still use git within ent, for the record; when you start doing time travel, you start to wonder, sometimes, what reality used to look like. git, enslaved to ent, will serenely keep track of all this. </p>

<h3 id="toc_4">Time travel</h3>

<p>Here&#39;s some unavoidable terminology: in ent world, there are two universes. In Universe A, time is entropic, irreversible, and can only be queried as to prior state (and only through the mechanism of recording that prior state). In Universe B, time is reversible and mutable, with a higher order that immutably tracks the paths of that mutation and can unwind the skein accordingly. </p>

<p>What? Say I have a file, and I rewind time to rename a function <code>foo()</code> to <code>bar()</code>. I have a path of git revisions that say that at such-and-such a time, my file structure contains certain data. Since I haven&#39;t done any time traveling (it&#39;s not for the faint of heart), Universe A (git land) is the same as Universe B (ent space). </p>

<p>So I rewind time, past several git boundaries, and merge. It works. Now, if I go back in time in Universe B, my function is called <code>bar()</code>. If I go back in time in Universe A, my function is called <code>foo()</code>, until the moment that I went back in time, at which point it&#39;s called <code>bar()</code>. </p>

<p>Universe A is reality, as it happened. Universe B is reality as we wish it happened. They are a powerful team. </p>

<h3 id="toc_5">Branch and Merge, again</h3>

<p>The model is in principle no different when multiple authors work on one code base. ent tracks who made each change, in addition to what the change is, as part of the atomic transformation. </p>

<p>To the degree that one ent is aware of another, they may trade branches. Moreover, when changes are propagated up the time stream, they may be offered to such other ents as the propagating ent may be aware. </p>

<p>That&#39;s a lot of maybes. This is code we&#39;re talking about; handle with care. The current paradigm is pull-only for revisions; ent can provide notifications that changes are available, and hand those changes off, but pushing code willy-nilly is a bad habit to get into. </p>

<p>That said, there is often a clear division between fixing mistakes in code and extending / changing functionality. It is often the case that library updates will fix broken things and break working things, and careful use of ent can separate these concerns, by rewinding a local tree to the point where bad input was created and correcting the mistake. </p>

<p>In the real world, code sometimes depends on buggy behavior, and in this case, you simply rewind the edit and are stuck in the familiar position of having to either freeze the library or change your local codebase. Either way, merely providing the distinction between &#39;this is as things always should have been&#39; and &#39;this is how we want things to be now&#39; can prove powerful. </p>
]]></content>
  </entry>
  
</feed>
